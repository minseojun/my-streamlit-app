# failog_app.py
# Streamlit app: failog (ê³„íš ì‹¤íŒ¨ ê¸°ë¡ â†’ ì›ì¸ ë¶„ë¥˜(ì €ì¥) â†’ ì£¼ê°„ ë¦¬í¬íŠ¸/íŠ¸ë Œë“œ/ë¦¬ë§ˆì¸ë”/ì½”ì¹­)
#
# âœ… ë³€ê²½ ì‚¬í•­(ìš”ì²­ ë°˜ì˜)
# - OpenAI API Keyë¥¼ "ì•±ì—ì„œ ì…ë ¥"í•´ì„œ ë™ì‘í•˜ë„ë¡ ìˆ˜ì • (í™˜ê²½ë³€ìˆ˜ ì˜ì¡´ X)
# - í‚¤ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ session_stateì—ë§Œ ì €ì¥(ë¸Œë¼ìš°ì € ì„¸ì…˜ ì¢…ë£Œ ì‹œ ì‚¬ë¼ì§)
# - ì›í•˜ë©´ "ë¡œì»¬ì— ì €ì¥(ì„¤ì • DB)" ì˜µì…˜ì„ ì¼¤ ìˆ˜ ìˆê²Œ ì œê³µ(ì„ íƒ)
#
# í¬í•¨ ê¸°ëŠ¥
# 1) ë°ì¼ë¦¬ ì²´í¬(ì„±ê³µ/ì‹¤íŒ¨ + ì‹¤íŒ¨ ì´ìœ  + ì›ì¸ ì¹´í…Œê³ ë¦¬ ì €ì¥)
# 2) ì›ì¸ ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬/íŠ¸ë Œë“œ(ì£¼ì°¨ë³„ ë¼ì¸ì°¨íŠ¸, ë¶„í¬ ë°”ì°¨íŠ¸)
# 3) ìŠµê´€/ëª©í‘œë³„ ì£¼ê°„ ë¦¬í¬íŠ¸(ì„±ê³µë¥ , ì‹¤íŒ¨ Top ì›ì¸, ë°˜ë³µ ì‹¤íŒ¨ ê°ì§€)
# 4) ì•Œë¦¼(ë¦¬ë§ˆì¸ë”)
#    - ì•±ì´ ì—´ë ¤ ìˆì„ ë•Œ: ì„¤ì • ì‹œê°„ëŒ€ì— ë¯¸ì²´í¬(pending) ìˆìœ¼ë©´ ë°°ë„ˆ/í† ìŠ¤íŠ¸
#    - OS/ìº˜ë¦°ë”ìš©: ë§¤ì¼ ë¦¬ë§ˆì¸ë” .ics ë‹¤ìš´ë¡œë“œ
# 5) ì½”ì¹­ ìƒì„±(ê³µí†µ ì›ì¸ 3ê°œ ì´ë‚´ + ì‹¤í–‰ê°€ëŠ¥ ì¡°ì–¸ + 2ì£¼ ì´ìƒ ë°˜ë³µ ì›ì¸ì— ì°½ì˜ ëŒ€ì•ˆ)
#    - OpenAI Key ì…ë ¥ ì‹œ LLM ê¸°ë°˜
#    - Key ë¯¸ì…ë ¥ ì‹œ Local(ê·œì¹™ ê¸°ë°˜)ë¡œ í´ë°±
#
# ì‹¤í–‰:
#   pip install streamlit pandas openai streamlit-autorefresh
#   streamlit run failog_app.py

import re
import json
import sqlite3
from datetime import datetime, date, timedelta, time
from typing import Optional, Dict, Any, List, Tuple

import pandas as pd
import streamlit as st

# Optional: autorefresh for reminder polling
try:
    from streamlit_autorefresh import st_autorefresh
except Exception:
    st_autorefresh = None

# OpenAI
try:
    from openai import OpenAI
except Exception:
    OpenAI = None


# -----------------------------
# Config
# -----------------------------
APP_TITLE = "failog â€” ì‹¤íŒ¨ë¥¼ ì‹¤í–‰ ì „ëµìœ¼ë¡œ ë°”ê¿”ì£¼ëŠ” ì½”ì¹­"
DB_PATH = "failog.db"
DEFAULT_TZ = "Asia/Seoul"


# -----------------------------
# Utilities
# -----------------------------
def now_iso():
    return datetime.now().isoformat(timespec="seconds")


def today_local() -> date:
    return date.today()


def week_start(d: date) -> date:
    return d - timedelta(days=d.weekday())


def normalize_text(text: str) -> str:
    t = (text or "").strip().lower()
    t = re.sub(r"\s+", " ", t)
    t = re.sub(r"[^\w\sê°€-í£]", "", t)
    return t


# -----------------------------
# DB Layer (SQLite) + Migrations
# -----------------------------
def get_conn():
    conn = sqlite3.connect(DB_PATH, check_same_thread=False)
    conn.execute("PRAGMA foreign_keys = ON;")
    return conn


def table_columns(conn, table: str) -> List[str]:
    cur = conn.cursor()
    cur.execute(f"PRAGMA table_info({table});")
    return [r[1] for r in cur.fetchall()]


def ensure_column(conn, table: str, col: str, ddl_type: str, default_sql: Optional[str] = None):
    cols = table_columns(conn, table)
    if col in cols:
        return
    dflt = f" DEFAULT {default_sql}" if default_sql is not None else ""
    conn.execute(f"ALTER TABLE {table} ADD COLUMN {col} {ddl_type}{dflt};")


def init_db():
    conn = get_conn()
    cur = conn.cursor()

    # plans
    cur.execute(
        """
        CREATE TABLE IF NOT EXISTS plans (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            title TEXT NOT NULL,
            active INTEGER NOT NULL DEFAULT 1,
            created_at TEXT NOT NULL
        );
        """
    )

    # daily logs (base)
    cur.execute(
        """
        CREATE TABLE IF NOT EXISTS daily_logs (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            log_date TEXT NOT NULL,
            plan_id INTEGER NOT NULL,
            status TEXT NOT NULL CHECK(status IN ('pending','success','fail')),
            reason TEXT,
            created_at TEXT NOT NULL,
            updated_at TEXT NOT NULL,
            UNIQUE(log_date, plan_id),
            FOREIGN KEY(plan_id) REFERENCES plans(id) ON DELETE CASCADE
        );
        """
    )

    # taxonomy
    cur.execute(
        """
        CREATE TABLE IF NOT EXISTS cause_taxonomy (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            name TEXT NOT NULL UNIQUE,
            description TEXT,
            keywords TEXT,
            active INTEGER NOT NULL DEFAULT 1,
            created_at TEXT NOT NULL,
            updated_at TEXT NOT NULL
        );
        """
    )

    # settings
    cur.execute(
        """
        CREATE TABLE IF NOT EXISTS settings (
            key TEXT PRIMARY KEY,
            value TEXT NOT NULL,
            updated_at TEXT NOT NULL
        );
        """
    )

    conn.commit()

    # migrations for daily_logs: cause fields
    ensure_column(conn, "daily_logs", "cause_name", "TEXT", None)
    ensure_column(conn, "daily_logs", "cause_source", "TEXT", "'none'")  # user|ai|rule|none
    ensure_column(conn, "daily_logs", "cause_confidence", "REAL", "0.0")
    ensure_column(conn, "daily_logs", "cause_updated_at", "TEXT", None)

    conn.commit()

    # seed taxonomy if empty
    n = cur.execute("SELECT COUNT(*) FROM cause_taxonomy;").fetchone()[0]
    if n == 0:
        seed = [
            ("ì‹œê°„/ì¼ì •", "íšŒì˜/ì•¼ê·¼/ì´ë™/ë§ˆê° ë“±ìœ¼ë¡œ ì‹œê°„ì´ ë°€ë¦¬ê±°ë‚˜ ê³„íš íƒ€ì´ë°ì´ ê¹¨ì§„ ê²½ìš°",
             ["ì‹œê°„", "ì•¼ê·¼", "íšŒì˜", "ì¼ì •", "ì•½ì†", "ë§ˆê°", "ì´ë™", "ì¶œê·¼", "ëŠ¦"]),
            ("ì—ë„ˆì§€/ì»¨ë””ì…˜", "í”¼ë¡œ/ìˆ˜ë©´/ì»¨ë””ì…˜ ì €í•˜ë¡œ ì‹¤í–‰ ì—ë„ˆì§€ê°€ ë¶€ì¡±í•œ ê²½ìš°",
             ["í”¼ê³¤", "ì¡¸ë¦¼", "ì ", "ì»¨ë””ì…˜", "ì§€ì¹¨", "ì•„íŒŒ", "ë‘í†µ"]),
            ("í™˜ê²½/ë°©í•´ìš”ì¸", "í°/SNS/ìœ íŠœë¸Œ/ì†ŒìŒ/ì¹¨ëŒ€ ë“± ë°©í•´ìê·¹ì´ ê°•í–ˆë˜ ê²½ìš°",
             ["í°", "íœ´ëŒ€í°", "ìœ íŠœë¸Œ", "sns", "ë°©í•´", "ì†ŒìŒ", "ì¹¨ëŒ€", "ê²Œì„", "ë„·í”Œ"]),
            ("ê³„íš/ì„¤ê³„", "ëª©í‘œê°€ ê³¼ë„í•˜ê±°ë‚˜ êµ¬ì²´ì„±ì´ ë¶€ì¡±í•´ì„œ ì‹œì‘/ìœ ì§€ê°€ ì–´ë ¤ì› ë˜ ê²½ìš°",
             ["ë„ˆë¬´", "ê³¼í•˜ê²Œ", "ë¬´ë¦¬", "ê³„íš", "ëª©í‘œ", "ë¶„ëŸ‰", "ìš°ì„ ìˆœìœ„", "ì •ë¦¬"]),
            ("ë™ê¸°/ì˜ë¯¸", "ì˜ìš• ì €í•˜/ê·€ì°®ìŒ/ë¯¸ë£¨ê¸°/ì˜ë¯¸ ë¶€ì¡±ìœ¼ë¡œ ì‹¤í–‰ì´ ëŠê¸´ ê²½ìš°",
             ["ì˜ìš•", "ë™ê¸°", "ê·€ì°®", "í•˜ê¸°ì‹«", "ì˜ë¯¸", "ë¯¸ë£¸", "ë¯¸ë£¨"]),
            ("ê¸°íƒ€(ëª…í™•í™” í•„ìš”)", "ë¶„ë¥˜ê°€ ì• ë§¤í•˜ê±°ë‚˜ ì´ìœ ê°€ ë¶ˆëª…í™•í•œ ê²½ìš°(ë‹¤ìŒ ê¸°ë¡ ë•Œ í•œ ë¬¸ì¥ ë” êµ¬ì²´í™”)", []),
        ]
        for name, desc, kws in seed:
            cur.execute(
                """
                INSERT INTO cause_taxonomy (name, description, keywords, active, created_at, updated_at)
                VALUES (?, ?, ?, 1, ?, ?)
                """,
                (name, desc, json.dumps(kws, ensure_ascii=False), now_iso(), now_iso()),
            )
        conn.commit()

    # seed settings defaults
    def set_default(key: str, value: str):
        cur.execute(
            "INSERT OR IGNORE INTO settings (key, value, updated_at) VALUES (?, ?, ?)",
            (key, value, now_iso()),
        )

    set_default("reminder_enabled", "true")
    set_default("reminder_time", "21:30")
    set_default("reminder_window_min", "15")
    set_default("reminder_poll_sec", "60")

    # optional: store api key (user can choose to enable)
    set_default("openai_api_key", "")
    set_default("openai_model", "gpt-4o-mini")

    conn.commit()
    conn.close()


# -----------------------------
# Settings
# -----------------------------
def upsert_setting(key: str, value: str):
    conn = get_conn()
    conn.execute(
        """
        INSERT INTO settings (key, value, updated_at)
        VALUES (?, ?, ?)
        ON CONFLICT(key) DO UPDATE SET value=excluded.value, updated_at=excluded.updated_at
        """,
        (key, value, now_iso()),
    )
    conn.commit()
    conn.close()


def get_setting(key: str, default: str) -> str:
    conn = get_conn()
    cur = conn.cursor()
    row = cur.execute("SELECT value FROM settings WHERE key=?", (key,)).fetchone()
    conn.close()
    return row[0] if row else default


# -----------------------------
# CRUD
# -----------------------------
def add_plan(title: str):
    conn = get_conn()
    conn.execute(
        "INSERT INTO plans (title, active, created_at) VALUES (?, 1, ?)",
        (title.strip(), now_iso()),
    )
    conn.commit()
    conn.close()


def set_plan_active(plan_id: int, active: bool):
    conn = get_conn()
    conn.execute("UPDATE plans SET active=? WHERE id=?", (1 if active else 0, plan_id))
    conn.commit()
    conn.close()


def list_plans(active_only: bool = False) -> pd.DataFrame:
    conn = get_conn()
    q = "SELECT id, title, active, created_at FROM plans"
    if active_only:
        q += " WHERE active=1"
    q += " ORDER BY id DESC"
    df = pd.read_sql_query(q, conn)
    conn.close()
    return df


def ensure_daily_rows(log_date: date):
    conn = get_conn()
    cur = conn.cursor()
    plans = cur.execute("SELECT id FROM plans WHERE active=1").fetchall()
    for (pid,) in plans:
        cur.execute(
            """
            INSERT OR IGNORE INTO daily_logs
              (log_date, plan_id, status, reason, created_at, updated_at, cause_name, cause_source, cause_confidence, cause_updated_at)
            VALUES (?, ?, 'pending', NULL, ?, ?, NULL, 'none', 0.0, NULL)
            """,
            (log_date.isoformat(), pid, now_iso(), now_iso()),
        )
    conn.commit()
    conn.close()


def get_daily_logs(log_date: date) -> pd.DataFrame:
    conn = get_conn()
    df = pd.read_sql_query(
        """
        SELECT dl.id, dl.log_date, dl.plan_id, p.title AS plan_title,
               dl.status, dl.reason,
               dl.cause_name, dl.cause_source, dl.cause_confidence,
               dl.updated_at
        FROM daily_logs dl
        JOIN plans p ON p.id = dl.plan_id
        WHERE dl.log_date = ?
        ORDER BY p.id DESC
        """,
        conn,
        params=(log_date.isoformat(),),
    )
    conn.close()
    return df


def update_log_success(log_id: int):
    conn = get_conn()
    conn.execute(
        """
        UPDATE daily_logs
        SET status='success', reason=NULL,
            cause_name=NULL, cause_source='none', cause_confidence=0.0, cause_updated_at=NULL,
            updated_at=?
        WHERE id=?
        """,
        (now_iso(), log_id),
    )
    conn.commit()
    conn.close()


def update_log_fail(
    log_id: int,
    reason: str,
    cause_name: Optional[str],
    cause_source: str,
    cause_confidence: float,
):
    conn = get_conn()
    conn.execute(
        """
        UPDATE daily_logs
        SET status='fail', reason=?,
            cause_name=?, cause_source=?, cause_confidence=?, cause_updated_at=?,
            updated_at=?
        WHERE id=?
        """,
        (
            (reason.strip() if reason else "ì´ìœ  ë¯¸ê¸°ë¡"),
            cause_name,
            cause_source,
            float(cause_confidence),
            now_iso(),
            now_iso(),
            log_id,
        ),
    )
    conn.commit()
    conn.close()


def update_log_pending(log_id: int):
    conn = get_conn()
    conn.execute(
        """
        UPDATE daily_logs
        SET status='pending', reason=NULL,
            cause_name=NULL, cause_source='none', cause_confidence=0.0, cause_updated_at=NULL,
            updated_at=?
        WHERE id=?
        """,
        (now_iso(), log_id),
    )
    conn.commit()
    conn.close()


def get_failures(start_date: date, end_date: date) -> pd.DataFrame:
    conn = get_conn()
    df = pd.read_sql_query(
        """
        SELECT dl.id, dl.log_date, dl.plan_id, p.title AS plan_title,
               dl.reason, dl.cause_name, dl.cause_source, dl.cause_confidence
        FROM daily_logs dl
        JOIN plans p ON p.id = dl.plan_id
        WHERE dl.status='fail'
          AND dl.log_date BETWEEN ? AND ?
        ORDER BY dl.log_date ASC
        """,
        conn,
        params=(start_date.isoformat(), end_date.isoformat()),
    )
    conn.close()
    return df


def get_logs_range(start_date: date, end_date: date, active_only: bool = False) -> pd.DataFrame:
    conn = get_conn()
    where_active = "AND p.active=1" if active_only else ""
    df = pd.read_sql_query(
        f"""
        SELECT dl.id, dl.log_date, dl.plan_id, p.title AS plan_title, p.active,
               dl.status, dl.reason,
               dl.cause_name, dl.cause_source, dl.cause_confidence
        FROM daily_logs dl
        JOIN plans p ON p.id = dl.plan_id
        WHERE dl.log_date BETWEEN ? AND ?
        {where_active}
        ORDER BY dl.log_date ASC, p.id DESC
        """,
        conn,
        params=(start_date.isoformat(), end_date.isoformat()),
    )
    conn.close()
    return df


# -----------------------------
# Taxonomy
# -----------------------------
def list_causes(active_only: bool = True) -> pd.DataFrame:
    conn = get_conn()
    q = "SELECT id, name, description, keywords, active, updated_at FROM cause_taxonomy"
    if active_only:
        q += " WHERE active=1"
    q += " ORDER BY id ASC"
    df = pd.read_sql_query(q, conn)
    conn.close()
    return df


def add_cause(name: str, description: str, keywords_list: List[str]):
    conn = get_conn()
    conn.execute(
        """
        INSERT INTO cause_taxonomy (name, description, keywords, active, created_at, updated_at)
        VALUES (?, ?, ?, 1, ?, ?)
        """,
        (name.strip(), description.strip(), json.dumps(keywords_list, ensure_ascii=False), now_iso(), now_iso()),
    )
    conn.commit()
    conn.close()


def set_cause_active(cause_id: int, active: bool):
    conn = get_conn()
    conn.execute(
        "UPDATE cause_taxonomy SET active=?, updated_at=? WHERE id=?",
        (1 if active else 0, now_iso(), cause_id),
    )
    conn.commit()
    conn.close()


# -----------------------------
# OpenAI helpers (KEY INPUT from UI)
# -----------------------------
def get_openai_client(api_key: str) -> OpenAI:
    if OpenAI is None:
        raise RuntimeError("openai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ì–´ìš”. pip install openai")
    if not api_key or not api_key.strip():
        raise RuntimeError("OpenAI API Keyê°€ ë¹„ì–´ ìˆì–´ìš”.")
    return OpenAI(api_key=api_key.strip())


# -----------------------------
# Classification (OpenAI / Fallback)
# -----------------------------
def fallback_classify_reason(reason: str, causes_df: pd.DataFrame) -> Tuple[str, float, str]:
    r = (reason or "").lower()
    best = ("ê¸°íƒ€(ëª…í™•í™” í•„ìš”)", 0.35)
    for _, row in causes_df.iterrows():
        name = row["name"]
        try:
            kws = json.loads(row["keywords"] or "[]")
        except Exception:
            kws = []
        if not kws:
            continue
        hits = sum(1 for kw in kws if kw and kw.lower() in r)
        if hits > 0:
            conf = min(0.55 + 0.1 * hits, 0.9)
            if conf > best[1]:
                best = (name, conf)
    return best[0], best[1], "rule"


def openai_classify_reason(api_key: str, model: str, reason: str, cause_names: List[str]) -> Tuple[str, float, str]:
    client = get_openai_client(api_key)
    prompt = f"""
ë„ˆëŠ” ì‚¬ìš©ìì˜ 'ê³„íš ì‹¤íŒ¨ ì´ìœ 'ë¥¼ ì•„ë˜ ì›ì¸ ì¹´í…Œê³ ë¦¬ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•´.
ì¹´í…Œê³ ë¦¬ ëª©ë¡: {json.dumps(cause_names, ensure_ascii=False)}

ì…ë ¥ ì‹¤íŒ¨ ì´ìœ :
{reason}

ê·œì¹™:
- ë°˜ë“œì‹œ ëª©ë¡ ì¤‘ í•˜ë‚˜ë§Œ ì„ íƒ
- ì¶œë ¥ì€ JSONë§Œ
í˜•ì‹:
{{"cause":"...", "confidence":0.0}}
confidenceëŠ” 0~1 (í™•ì‹ ì´ ë‚®ìœ¼ë©´ 0.4~0.6)
""".strip()

    resp = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": "Return valid JSON only."},
            {"role": "user", "content": prompt},
        ],
        temperature=0.2,
    )
    text = resp.choices[0].message.content.strip()
    try:
        obj = json.loads(text)
    except json.JSONDecodeError:
        m = re.search(r"\{.*\}", text, flags=re.DOTALL)
        if not m:
            raise
        obj = json.loads(m.group(0))

    cause = str(obj.get("cause", "")).strip()
    conf = float(obj.get("confidence", 0.5))
    if cause not in cause_names:
        cause = "ê¸°íƒ€(ëª…í™•í™” í•„ìš”)" if "ê¸°íƒ€(ëª…í™•í™” í•„ìš”)" in cause_names else cause_names[-1]
        conf = min(conf, 0.55)
    conf = max(0.0, min(1.0, conf))
    return cause, conf, "ai"


def classify_reason(reason: str, api_key: str, model: str) -> Tuple[str, float, str]:
    causes_df = list_causes(active_only=True)
    cause_names = causes_df["name"].tolist()

    if not (reason or "").strip():
        return ("ê¸°íƒ€(ëª…í™•í™” í•„ìš”)" if "ê¸°íƒ€(ëª…í™•í™” í•„ìš”)" in cause_names else cause_names[-1], 0.35, "rule")

    # Prefer OpenAI if key exists
    if api_key and api_key.strip():
        try:
            return openai_classify_reason(api_key, model, reason, cause_names)
        except Exception:
            # fall back
            pass

    return fallback_classify_reason(reason, causes_df)


# -----------------------------
# Repeated detection (>=14 days) by CAUSE (plan_id + cause_name)
# -----------------------------
def detect_repeated_causes_2w(failures_df: pd.DataFrame) -> Dict[Tuple[int, str], bool]:
    if failures_df.empty:
        return {}
    df = failures_df.copy()
    df["log_date"] = pd.to_datetime(df["log_date"]).dt.date
    df["cause_name"] = df["cause_name"].fillna("ê¸°íƒ€(ëª…í™•í™” í•„ìš”)")
    flags: Dict[Tuple[int, str], bool] = {}
    for (pid, cause), g in df.groupby(["plan_id", "cause_name"]):
        dates = sorted(g["log_date"].tolist())
        if len(dates) >= 2 and (dates[-1] - dates[0]).days >= 14:
            flags[(int(pid), str(cause))] = True
    return flags


# -----------------------------
# Coaching Engine
# -----------------------------
COACH_SCHEMA_HINT = """
ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥í•´. (ì„¤ëª…/ë§ˆí¬ë‹¤ìš´ ê¸ˆì§€)
í˜•ì‹:
{
  "top_causes": [
    {
      "cause": "ì›ì¸ ì¹´í…Œê³ ë¦¬ ì´ë¦„(ì§§ê²Œ)",
      "summary": "ì™œ ì´ê²Œ ê³µí†µ ì›ì¸ì¸ì§€ 2~3ë¬¸ì¥",
      "actionable_advice": ["í˜„ì‹¤ì  ì¡°ì–¸ 1", "í˜„ì‹¤ì  ì¡°ì–¸ 2", "í˜„ì‹¤ì  ì¡°ì–¸ 3"],
      "creative_advice_when_repeated_2w": ["(í•´ë‹¹ ì›ì¸ì´ 2ì£¼ ì´ìƒ ë°˜ë³µëœ í•­ëª©ì´ ìˆì„ ë•Œë§Œ) ì°½ì˜ì  ì¡°ì–¸ 1", "..."]
    }
  ],
  "tone_note": "ì „ì²´ í†¤ì´ ë¹„ë‚œ ì—†ì´ ì½”ì¹­ ì¤‘ì‹¬ì¸ì§€ ì ê²€í•˜ëŠ” í•œ ë¬¸ì¥"
}
ê·œì¹™:
- top_causesëŠ” ìµœëŒ€ 3ê°œ
- actionable_adviceëŠ” 'ì§€ê¸ˆ ë‹¹ì¥ ì‹¤í–‰' ê°€ëŠ¥í•œ ìˆ˜ì¤€(ì‘ê³  êµ¬ì²´ì )ìœ¼ë¡œ
- 'ë¹„ë‚œ/ìì±… ìœ ë„' í‘œí˜„ ê¸ˆì§€
- 2ì£¼ ì´ìƒ ë°˜ë³µ(repeated_2w=true)ëœ ì›ì¸ì´ ìˆìœ¼ë©´, í•´ë‹¹ ì›ì¸ì— creative_advice_when_repeated_2wë¥¼ ë°˜ë“œì‹œ í¬í•¨
- ë°˜ë³µ ì›ì¸ì´ ì—†ìœ¼ë©´ creative_advice_when_repeated_2wëŠ” ë¹ˆ ë°°ì—´([])ë¡œ
"""


def build_coach_prompt(items: List[Dict[str, Any]]) -> str:
    return f"""
ë„ˆëŠ” 'ì‹¤íŒ¨ ê¸°ë¡ì„ ì‹¤í–‰ ì „ëµìœ¼ë¡œ ë°”ê¾¸ëŠ”' ì½”ì¹­ AIì•¼.
ì‚¬ìš©ìê°€ ì ì€ "ì‹¤íŒ¨ ì´ìœ "ì™€ "ì›ì¸ ì¹´í…Œê³ ë¦¬" ë°ì´í„°ë¥¼ ë³´ê³  ê³µí†µ ì›ì¸ì„ ìµœëŒ€ 3ê°€ì§€ë¡œ ë¬¶ê³ ,
ê° ì›ì¸ì— ëŒ€í•´ ì‹¤í–‰ ê°€ëŠ¥í•˜ê³  í˜„ì‹¤ì ì¸ ê°œì„  ì¡°ì–¸ì„ ì œì‹œí•´.
ì¶”ê°€ ê·œì¹™: ë§Œì•½ repeated_2w=true ì¸ ì›ì¸(ê°™ì€ ì›ì¸ì´ 2ì£¼ ì´ìƒ ë°˜ë³µ)ì´ ìˆë‹¤ë©´,
ê·¸ ì›ì¸ì— ëŒ€í•´ ê¸°ì¡´ ì¡°ì–¸ê³¼ ê²°ì´ ë‹¤ë¥¸ "ì°½ì˜ì ì¸ ëŒ€ì•ˆ ì¡°ì–¸"ë„ ì œì‹œí•´.
í†¤ì€ ì ˆëŒ€ ë¹„ë‚œí•˜ì§€ ë§ê³ , ì½”ì¹­/ê²©ë ¤ ì¤‘ì‹¬ìœ¼ë¡œ.

ì…ë ¥ ë°ì´í„°:
{json.dumps(items, ensure_ascii=False, indent=2)}

{COACH_SCHEMA_HINT}
""".strip()


def openai_coach(api_key: str, model: str, items: List[Dict[str, Any]]) -> Dict[str, Any]:
    client = get_openai_client(api_key)
    resp = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": "You are a supportive coaching assistant. Output must be valid JSON only."},
            {"role": "user", "content": build_coach_prompt(items)},
        ],
        temperature=0.7,
    )
    text = resp.choices[0].message.content.strip()
    try:
        return json.loads(text)
    except json.JSONDecodeError:
        m = re.search(r"\{.*\}", text, flags=re.DOTALL)
        if not m:
            raise
        return json.loads(m.group(0))


def fallback_coach(items: List[Dict[str, Any]]) -> Dict[str, Any]:
    if not items:
        return {"top_causes": [], "tone_note": "ê¸°ë¡ì´ ë¹„ì–´ ìˆì–´ ë¶„ì„ ëŒ€ì‹  ë‹¤ìŒ ê¸°ë¡ì„ ê¸°ë‹¤ë¦¬ê³  ìˆì–´ìš”."}

    df = pd.DataFrame(items)
    counts = df["cause"].value_counts().head(3)

    top_causes = []
    for cause, _cnt in counts.items():
        sub = df[df["cause"] == cause]
        repeated = bool(sub["repeated_2w"].fillna(False).any())

        actionable = [
            "ì‹¤íŒ¨ê°€ ë‚œ ë‚ ì˜ 'ì²« ì¥ì• ë¬¼'ë§Œ í•œ ë¬¸ì¥ìœ¼ë¡œ ì ê³ , ë‚´ì¼ì€ ê·¸ ì¥ì• ë¬¼ì„ í”¼í•˜ëŠ” ì¥ì¹˜ë¥¼ ë”± 1ê°œë§Œ ì¶”ê°€í•´ìš”(ì˜ˆ: íšŒì˜ í›„ 10ë¶„ íœ´ì‹ ê³ ì •).",
            "ê³„íšì„ 'ì‹œì‘ 2ë¶„ ë²„ì „'ìœ¼ë¡œ ì¶•ì†Œí•´ì„œ ì§„ì…ì¥ë²½ì„ ë‚®ì¶°ìš”(ì˜ˆ: ìš´ë™ 20ë¶„ â†’ ìŠ¤íŠ¸ë ˆì¹­ 2ë¶„ë§Œ).",
            "ì‹¤íŒ¨ê°€ ë§ì´ ë‚˜ëŠ” ì‹œê°„ëŒ€ë¥¼ íŒŒì•…í•´ì„œ, ê·¸ ì‹œê°„ì—” ë°©í•´ìš”ì¸ì„ ë¯¸ë¦¬ ì¹˜ìš°ëŠ” ë£¨í‹´(ì•Œë¦¼ ë„ê¸°/ì¥ì†Œ ì´ë™/ë„êµ¬ ë¯¸ë¦¬ ì¤€ë¹„)ì„ ë§Œë“¤ì–´ìš”.",
        ]
        creative = []
        if repeated:
            creative = [
                "2ì£¼ ì´ìƒ ë°˜ë³µì´ë©´, ëª©í‘œë¥¼ 'ì„±ê³¼'ê°€ ì•„ë‹ˆë¼ 'ì¡°ê±´ ì‹¤í—˜'ìœ¼ë¡œ ë°”ê¿”ìš”. ì˜ˆ: 'ìš´ë™ ì„±ê³µ' â†’ 'ìš´ë™ì´ ë˜ëŠ” ì¡°ê±´ ì°¾ê¸°'ë¥¼ 1ì£¼ì¼ë§Œ ì‹¤í—˜.",
                "íŠ¸ë¦¬ê±°ë¥¼ ì™„ì „íˆ ë°”ê¿”ë´ìš”. ì‹œê°„(ì €ë…â†’ì•„ì¹¨), ì¥ì†Œ(ì§‘â†’ì¹´í˜/í—¬ìŠ¤ì¥), ë°©ì‹(í˜¼ìâ†’ë™ë£Œ/í´ë˜ìŠ¤) ì¤‘ í•˜ë‚˜ë§Œ êµì²´í•´ìš”.",
            ]

        top_causes.append(
            {
                "cause": cause,
                "summary": f"ìµœê·¼ ê¸°ë¡ì—ì„œ '{cause}' ìœ í˜•ì´ ìì£¼ ë“±ì¥í•´ìš”. ì´ê±´ ì˜ì§€ ë¬¸ì œê°€ ì•„ë‹ˆë¼ 'ì¡°ê±´/ì„¤ê³„' ì¡°ì •ìœ¼ë¡œ ê°œì„ ë  ê°€ëŠ¥ì„±ì´ í° ì‹ í˜¸ì˜ˆìš”.",
                "actionable_advice": actionable,
                "creative_advice_when_repeated_2w": creative if repeated else [],
            }
        )

    return {"top_causes": top_causes, "tone_note": "ì‹¤íŒ¨ë¥¼ íƒ“ì´ ì•„ë‹ˆë¼ 'ì¡°ì • ê°€ëŠ¥í•œ ì¡°ê±´ ë°ì´í„°'ë¡œ ë‹¤ë£¨ëŠ” í†¤ì„ ìœ ì§€í–ˆì–´ìš”."}


def run_coaching(api_key: str, model: str, items: List[Dict[str, Any]]) -> Tuple[Dict[str, Any], str]:
    # If key exists, try OpenAI, else fallback
    if api_key and api_key.strip():
        try:
            return openai_coach(api_key, model, items), "OpenAI"
        except Exception as e:
            # Show a gentle hint in UI; still return fallback
            st.warning(f"OpenAI í˜¸ì¶œì— ì‹¤íŒ¨í•´ì„œ ë¡œì»¬ ì½”ì¹­ìœ¼ë¡œ ëŒ€ì²´í–ˆì–´ìš”. (ì›ì¸: {type(e).__name__})")
            return fallback_coach(items), "Local"
    return fallback_coach(items), "Local"


# -----------------------------
# Reminder: in-app + .ics
# -----------------------------
def parse_hhmm(s: str) -> time:
    s = (s or "").strip()
    m = re.match(r"^(\d{1,2}):(\d{2})$", s)
    if not m:
        return time(21, 30)
    hh, mm = int(m.group(1)), int(m.group(2))
    hh = max(0, min(23, hh))
    mm = max(0, min(59, mm))
    return time(hh, mm)


def should_show_reminder(now_dt: datetime, reminder_t: time, window_min: int) -> bool:
    target = datetime.combine(now_dt.date(), reminder_t)
    delta = abs((now_dt - target).total_seconds()) / 60.0
    return delta <= float(window_min)


def count_pending_today(d: date) -> int:
    ensure_daily_rows(d)
    conn = get_conn()
    cur = conn.cursor()
    row = cur.execute(
        """
        SELECT COUNT(*) FROM daily_logs dl
        JOIN plans p ON p.id=dl.plan_id
        WHERE dl.log_date=? AND p.active=1 AND dl.status='pending'
        """,
        (d.isoformat(),),
    ).fetchone()
    conn.close()
    return int(row[0] if row else 0)


def build_daily_ics(reminder_t: time) -> str:
    dtstamp = datetime.utcnow().strftime("%Y%m%dT%H%M%SZ")
    start = datetime.combine(today_local(), reminder_t).strftime("%Y%m%dT%H%M%S")
    uid = f"failog-reminder-{dtstamp}@local"
    return f"""BEGIN:VCALENDAR
VERSION:2.0
PRODID:-//failog//Reminder//EN
CALSCALE:GREGORIAN
BEGIN:VEVENT
UID:{uid}
DTSTAMP:{dtstamp}
DTSTART:{start}
DURATION:PT10M
RRULE:FREQ=DAILY
SUMMARY:failog ë°ì¼ë¦¬ ì²´í¬ ë¦¬ë§ˆì¸ë”
DESCRIPTION:ì˜¤ëŠ˜ì˜ ê³„íšì„ ì„±ê³µ/ì‹¤íŒ¨ë¡œ ì²´í¬í•˜ê³ , ì‹¤íŒ¨ë¼ë©´ ì´ìœ ë¥¼ í•œ ë¬¸ì¥ ê¸°ë¡í•´ìš”.
END:VEVENT
END:VCALENDAR
"""


# -----------------------------
# Sidebar: OpenAI Key UI
# -----------------------------
def sidebar_openai_panel():
    st.sidebar.header("ğŸ”‘ OpenAI ì„¤ì •")

    # Load defaults from DB (optional) for convenience
    db_model = get_setting("openai_model", "gpt-4o-mini")
    db_key = get_setting("openai_api_key", "")

    if "openai_api_key" not in st.session_state:
        st.session_state["openai_api_key"] = ""  # default empty

    # input
    api_key = st.sidebar.text_input(
        "OpenAI API Key",
        value=st.session_state["openai_api_key"],
        type="password",
        placeholder="sk-...",
        help="ê¸°ë³¸ì ìœ¼ë¡œ ì„¸ì…˜ì—ë§Œ ì €ì¥ë¼ìš”(ë¸Œë¼ìš°ì € ë‹«ìœ¼ë©´ ì‚¬ë¼ì§).",
    )
    st.session_state["openai_api_key"] = api_key

    model = st.sidebar.text_input("ëª¨ë¸", value=db_model, help="ì˜ˆ: gpt-4o-mini / gpt-4.1-mini ë“±")
    st.sidebar.caption("í‚¤ê°€ ë¹„ì–´ ìˆìœ¼ë©´ ë¡œì»¬(ê·œì¹™ ê¸°ë°˜)ë¡œ ë™ì‘í•©ë‹ˆë‹¤.")

    # optional persistence
    persist = st.sidebar.toggle("í‚¤ë¥¼ ë¡œì»¬(DB)ì— ì €ì¥", value=False, help="ê³µìš© PCì—ì„œëŠ” ë¹„ì¶”ì²œ")
    if st.sidebar.button("ì„¤ì • ì €ì¥", use_container_width=True):
        upsert_setting("openai_model", model.strip() or "gpt-4o-mini")
        if persist:
            upsert_setting("openai_api_key", api_key.strip())
            st.sidebar.success("ëª¨ë¸/í‚¤ë¥¼ ì €ì¥í–ˆì–´ìš”.")
        else:
            upsert_setting("openai_api_key", "")
            st.sidebar.success("ëª¨ë¸ë§Œ ì €ì¥í–ˆê³ , í‚¤ëŠ” ì„¸ì…˜ì—ë§Œ ë‚¨ê²¨ë‘ì—ˆì–´ìš”.")

    # If user previously stored key in DB and wants to use it:
    use_db_key = st.sidebar.toggle("ì €ì¥ëœ í‚¤ ì‚¬ìš©", value=False, help="DBì— ì €ì¥ëœ í‚¤ê°€ ìˆì„ ë•Œë§Œ ì˜ë¯¸ ìˆì–´ìš”.")
    effective_key = api_key.strip()
    if use_db_key and db_key.strip():
        effective_key = db_key.strip()

    return effective_key, (model.strip() or "gpt-4o-mini")


# -----------------------------
# Main App
# -----------------------------
def main():
    st.set_page_config(page_title="failog", page_icon="ğŸ§­", layout="wide")
    init_db()

    # Sidebar OpenAI
    effective_api_key, openai_model = sidebar_openai_panel()

    # Reminder settings
    reminder_enabled = get_setting("reminder_enabled", "true").lower() == "true"
    reminder_time = parse_hhmm(get_setting("reminder_time", "21:30"))
    reminder_window = int(get_setting("reminder_window_min", "15"))
    poll_sec = int(get_setting("reminder_poll_sec", "60"))

    if reminder_enabled and st_autorefresh is not None:
        st_autorefresh(interval=poll_sec * 1000, key="reminder_refresh")

    # In-app reminder banner
    if reminder_enabled:
        pending = count_pending_today(today_local())
        if pending > 0 and should_show_reminder(datetime.now(), reminder_time, reminder_window):
            st.toast(f"ë¦¬ë§ˆì¸ë”: ì•„ì§ ì²´í¬í•˜ì§€ ì•Šì€ í•­ëª©ì´ {pending}ê°œ ìˆì–´ìš”. (ê°€ë³ê²Œ ì²´í¬ë§Œ í•´ë„ ì¶©ë¶„í•´ìš”)", icon="â°")
            st.info(f"â° ì˜¤ëŠ˜ ì²´í¬ê°€ ì•„ì§ {pending}ê°œ ë‚¨ì•„ ìˆì–´ìš”. ì‹¤íŒ¨ì—¬ë„ ê´œì°®ì•„ìš”. í•œ ë¬¸ì¥ë§Œ ë‚¨ê¸°ë©´ ë‚´ì¼ì´ ì‰¬ì›Œì ¸ìš”.")

    st.title(APP_TITLE)
    st.caption("ì‹¤íŒ¨ëŠ” â€˜íƒ“â€™ì´ ì•„ë‹ˆë¼ â€˜ì¡°ê±´ ë°ì´í„°â€™ì˜ˆìš”. ë¹„ë‚œ ì—†ì´ ì½”ì¹­ìœ¼ë¡œ ë°”ê¿”ìš”.")

    tab_daily, tab_report, tab_analysis, tab_manage = st.tabs(
        ["âœ… ë°ì¼ë¦¬ ì²´í¬", "ğŸ—“ï¸ ì£¼ê°„ ë¦¬í¬íŠ¸", "ğŸ“ˆ ì›ì¸ íŠ¸ë Œë“œ & ì½”ì¹­", "âš™ï¸ ê´€ë¦¬(ê³„íš/ì›ì¸/ì•Œë¦¼)"]
    )

    # -------------------------
    # Tab 1: Daily
    # -------------------------
    with tab_daily:
        colL, colR = st.columns([1, 2])

        with colL:
            selected_date = st.date_input("ë‚ ì§œ", value=today_local(), key="daily_date")
            ensure_daily_rows(selected_date)
            st.subheader("ì˜¤ëŠ˜ì˜ í•œ ì¤„ ì½”ì¹­")
            st.write("ì‹¤íŒ¨ëŠ” â€˜ë‚´ê°€ ë¶€ì¡±í•¨â€™ì´ ì•„ë‹ˆë¼, **ì¡°ê±´ì´ ì•ˆ ë§ì•˜ë‹¤ëŠ” ì‹ í˜¸**ì¼ ë•Œê°€ ë§ì•„ìš”.")

        with colR:
            st.subheader("ë°ì¼ë¦¬ ê³„íš ë¦¬ìŠ¤íŠ¸")
            df = get_daily_logs(selected_date)
            causes_df = list_causes(active_only=True)
            cause_names = causes_df["name"].tolist()

            if df.empty:
                st.warning("í™œì„±í™”ëœ ê³„íšì´ ì—†ì–´ìš”. 'ê´€ë¦¬'ì—ì„œ ê³„íšì„ ì¶”ê°€í•´ ì£¼ì„¸ìš”.")
            else:
                for _, row in df.iterrows():
                    with st.container(border=True):
                        c1, c2 = st.columns([4, 6])
                        with c1:
                            st.markdown(f"**{row['plan_title']}**")
                            st.caption(f"ìƒíƒœ: `{row['status']}`")
                            if row.get("cause_name"):
                                st.caption(
                                    f"ì›ì¸: {row['cause_name']} ({row.get('cause_source','')}, {row.get('cause_confidence',0):.2f})"
                                )

                        with c2:
                            b1, b2, b3 = st.columns([1, 1, 1])
                            with b1:
                                if st.button("ì„±ê³µ âœ…", key=f"succ_{row['id']}"):
                                    update_log_success(int(row["id"]))
                                    st.success("ì„±ê³µ ì²´í¬ ì™„ë£Œ!")
                                    st.rerun()
                            with b2:
                                if st.button("ëŒ€ê¸° â†©ï¸", key=f"pend_{row['id']}"):
                                    update_log_pending(int(row["id"]))
                                    st.info("ëŒ€ê¸°ë¡œ ë˜ëŒë ¸ì–´ìš”.")
                                    st.rerun()
                            with b3:
                                st.write("")

                            reason_key = f"reason_{row['id']}"
                            cause_key = f"cause_{row['id']}"

                            default_reason = row["reason"] if row["reason"] else ""
                            reason = st.text_input("ì‹¤íŒ¨ ì´ìœ (í•œ ë¬¸ì¥)", value=default_reason, key=reason_key)

                            default_cause = row["cause_name"] if row["cause_name"] in cause_names else "ìë™ ë¶„ë¥˜"
                            options = ["ìë™ ë¶„ë¥˜"] + cause_names
                            cause_sel = st.selectbox(
                                "ì›ì¸ ì¹´í…Œê³ ë¦¬",
                                options=options,
                                index=options.index(default_cause) if default_cause in options else 0,
                                key=cause_key,
                            )

                            if st.button("ì‹¤íŒ¨ âŒ ì €ì¥", key=f"fail_save_{row['id']}"):
                                if cause_sel == "ìë™ ë¶„ë¥˜":
                                    cause, conf, src = classify_reason(reason, effective_api_key, openai_model)
                                else:
                                    cause, conf, src = cause_sel, 1.0, "user"
                                update_log_fail(int(row["id"]), reason, cause, src, conf)
                                st.warning("ì‹¤íŒ¨ ì²´í¬ ì €ì¥ ì™„ë£Œ! ê¸°ë¡ì„ ë‚¨ê¸´ ê²ƒ ìì²´ê°€ ì´ë¯¸ ë‹¤ìŒ ì„±ê³µ í™•ë¥ ì„ ì˜¬ë ¸ì–´ìš”.")
                                st.rerun()

    # -------------------------
    # Tab 2: Weekly Report
    # -------------------------
    with tab_report:
        st.subheader("ìŠµê´€/ëª©í‘œë³„ ì£¼ê°„ ë¦¬í¬íŠ¸")
        end_d = st.date_input("ë¦¬í¬íŠ¸ ì¢…ë£Œì¼", value=today_local(), key="report_end")
        ws = week_start(end_d)
        we = ws + timedelta(days=6)
        st.caption(f"ì£¼ê°„ ë²”ìœ„: {ws.isoformat()} ~ {we.isoformat()} (ì›”~ì¼)")

        logs = get_logs_range(ws, we, active_only=False)
        if logs.empty:
            st.info("ì´ ì£¼ì°¨ì—ëŠ” ê¸°ë¡ì´ ì—†ì–´ìš”.")
        else:
            x = logs.copy()
            x["is_success"] = (x["status"] == "success").astype(int)
            x["is_fail"] = (x["status"] == "fail").astype(int)
            x["is_pending"] = (x["status"] == "pending").astype(int)
            summary = x.groupby(["plan_id", "plan_title"], as_index=False).agg(
                success=("is_success", "sum"),
                fail=("is_fail", "sum"),
                pending=("is_pending", "sum"),
            )
            summary["checked"] = summary["success"] + summary["fail"]
            summary["success_rate"] = summary.apply(lambda r: (r["success"] / r["checked"]) if r["checked"] else 0.0, axis=1)
            summary_show = summary.sort_values(["success_rate", "checked"], ascending=[False, False]).copy()
            summary_show["success_rate"] = (summary_show["success_rate"] * 100).round(1).astype(str) + "%"
            st.dataframe(summary_show, use_container_width=True, hide_index=True)

            st.markdown("### ê³„íšë³„ ìƒì„¸")
            failures = logs[logs["status"] == "fail"].copy()
            failures["cause_name"] = failures["cause_name"].fillna("ê¸°íƒ€(ëª…í™•í™” í•„ìš”)")
            repeated_flags = detect_repeated_causes_2w(get_failures(ws - timedelta(days=21), we))

            for _, row in summary.sort_values(["success_rate", "checked"], ascending=[False, False]).iterrows():
                pid, title = int(row["plan_id"]), row["plan_title"]
                with st.container(border=True):
                    st.markdown(f"#### {title}")

                    sub = logs[logs["plan_id"] == pid].copy()
                    succ = int((sub["status"] == "success").sum())
                    fail = int((sub["status"] == "fail").sum())
                    pend = int((sub["status"] == "pending").sum())
                    checked = succ + fail
                    rate = (succ / checked) if checked else 0.0

                    c1, c2, c3, c4 = st.columns(4)
                    c1.metric("ì„±ê³µ", succ)
                    c2.metric("ì‹¤íŒ¨", fail)
                    c3.metric("ëŒ€ê¸°", pend)
                    c4.metric("ì£¼ê°„ ì„±ê³µë¥ ", f"{rate*100:.1f}%")

                    fsub = failures[failures["plan_id"] == pid]
                    if fsub.empty:
                        st.success("ì´ë²ˆ ì£¼ì—ëŠ” ì‹¤íŒ¨ ê¸°ë¡ì´ ì—†ì–´ìš”. ì´ íë¦„ì„ ê°€ë³ê²Œ ìœ ì§€í•´ìš”.")
                    else:
                        topc = fsub["cause_name"].value_counts().head(3)
                        st.write("ì‹¤íŒ¨ Top ì›ì¸:")
                        for cause, cnt in topc.items():
                            rep = repeated_flags.get((pid, str(cause)), False)
                            tag = " (2ì£¼+ ë°˜ë³µ ì‹ í˜¸)" if rep else ""
                            st.write(f"- {cause}: {cnt}íšŒ{tag}")

                        with st.expander("ì‹¤íŒ¨ ê¸°ë¡(ì´ìœ /ì›ì¸) ë³´ê¸°", expanded=False):
                            view = fsub[["log_date", "reason", "cause_name", "cause_source", "cause_confidence"]].copy()
                            st.dataframe(view, use_container_width=True, hide_index=True)

    # -------------------------
    # Tab 3: Trends & Coaching
    # -------------------------
    with tab_analysis:
        st.subheader("ì›ì¸ ì¹´í…Œê³ ë¦¬ íŠ¸ë Œë“œ & ì½”ì¹­")
        colA, colB, colC = st.columns([1, 1, 2])
        with colA:
            days = st.selectbox("ë¶„ì„ ê¸°ê°„(ì¼)", [7, 14, 21, 30, 60, 90], index=1, key="an_days")
        with colB:
            end_d = st.date_input("ì¢…ë£Œì¼", value=today_local(), key="an_end")
        with colC:
            st.caption("ì €ì¥ëœ ì›ì¸ ì¹´í…Œê³ ë¦¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¶„í¬/íŠ¸ë Œë“œë¥¼ ê·¸ë¦¬ê³ , ê³µí†µ ì›ì¸ 3ê°œ ì´ë‚´ ì½”ì¹­ì„ ìƒì„±í•´ìš”.")
            st.caption("ê°™ì€ ì›ì¸ì´ 2ì£¼ ì´ìƒ ë°˜ë³µë˜ë©´(ì›ì¸ ë‹¨ìœ„) í•´ë‹¹ ì›ì¸ì— ì°½ì˜ì  ëŒ€ì•ˆì„ ì¶”ê°€í•©ë‹ˆë‹¤.")

        start_d = end_d - timedelta(days=int(days) - 1)
        failures_df = get_failures(start_d, end_d)

        st.markdown("#### ì›ì¸ ì €ì¥ ìƒíƒœ")
        missing = int(failures_df["cause_name"].isna().sum()) if not failures_df.empty else 0
        st.write(f"- ì´ ê¸°ê°„ ì‹¤íŒ¨ ì¤‘ ì›ì¸ ë¯¸ì €ì¥: **{missing}ê±´**")
        backfill = st.checkbox("ì´ ê¸°ê°„ì˜ ì›ì¸ ë¯¸ì €ì¥ ì‹¤íŒ¨ë¥¼ ìë™ ë¶„ë¥˜í•´ì„œ DBì— ì €ì¥(ì¶”ì²œ)", value=False)

        if backfill and missing > 0:
            for _, r in failures_df[failures_df["cause_name"].isna()].iterrows():
                cid = int(r["id"])
                reason = r["reason"] or ""
                cause, conf, src = classify_reason(reason, effective_api_key, openai_model)
                conn = get_conn()
                conn.execute(
                    """
                    UPDATE daily_logs
                    SET cause_name=?, cause_source=?, cause_confidence=?, cause_updated_at=?, updated_at=?
                    WHERE id=?
                    """,
                    (cause, src, float(conf), now_iso(), now_iso(), cid),
                )
                conn.commit()
                conn.close()
            st.success("ìë™ ë¶„ë¥˜ ì €ì¥ ì™„ë£Œ! (ë‹¤ìŒ ë¶„ì„ì´ ë” ì •í™•í•´ì ¸ìš”)")
            failures_df = get_failures(start_d, end_d)

        if failures_df.empty:
            st.info("ì´ ê¸°ê°„ì—” ì‹¤íŒ¨ ê¸°ë¡ì´ ì—†ì–´ìš”. ğŸ‘ ì§€ê¸ˆì˜ ë¦¬ë“¬ì„ ìœ ì§€í•´ë„ ì¶©ë¶„íˆ ì¢‹ìŠµë‹ˆë‹¤.")
        else:
            failures_df = failures_df.copy()
            failures_df["cause_name"] = failures_df["cause_name"].fillna("ê¸°íƒ€(ëª…í™•í™” í•„ìš”)")
            failures_df["log_date"] = pd.to_datetime(failures_df["log_date"]).dt.date

            st.markdown("#### ì›ì¸ ë¶„í¬")
            dist = failures_df["cause_name"].value_counts().reset_index()
            dist.columns = ["cause", "count"]
            st.dataframe(dist, use_container_width=True, hide_index=True)
            st.bar_chart(dist.set_index("cause"))

            st.markdown("#### ì›ì¸ íŠ¸ë Œë“œ(ì£¼ì°¨ë³„)")
            tmp = failures_df.copy()
            tmp["week"] = tmp["log_date"].apply(lambda d: week_start(d).isoformat())
            trend = tmp.groupby(["week", "cause_name"]).size().reset_index(name="count")
            pivot = trend.pivot(index="week", columns="cause_name", values="count").fillna(0).sort_index()
            st.line_chart(pivot)

            repeated_flags = detect_repeated_causes_2w(failures_df)

            items = []
            for _, r in failures_df.iterrows():
                pid = int(r["plan_id"])
                cause = str(r["cause_name"])
                items.append(
                    {
                        "plan_title": r["plan_title"],
                        "date": str(r["log_date"]),
                        "reason": r["reason"] or "",
                        "cause": cause,
                        "repeated_2w": bool(repeated_flags.get((pid, cause), False)),
                    }
                )

            st.markdown("#### ì½”ì¹­ ìƒì„±")
            run_btn = st.button("ì½”ì¹­ ìƒì„±/ê°±ì‹ ", type="primary", key="coach_run")

            if run_btn or ("coach_result" not in st.session_state):
                result, engine = run_coaching(effective_api_key, openai_model, items)
                st.session_state["coach_result"] = result
                st.session_state["coach_engine"] = engine

            result = st.session_state.get("coach_result", {})
            engine = st.session_state.get("coach_engine", "Local")
            st.write(f"ì‚¬ìš© ì—”ì§„: **{engine}**  |  ëª¨ë¸: **{openai_model}**")

            top_causes = result.get("top_causes", []) if isinstance(result.get("top_causes", []), list) else []
            if not top_causes:
                st.info("ì•„ì§ ë¶„ë¥˜í•  ë§Œí¼ ë°ì´í„°ê°€ ë¶€ì¡±í•´ìš”. ì‹¤íŒ¨ ì´ìœ ë¥¼ í•œ ë¬¸ì¥ì´ë¼ë„ ë” ìŒ“ì•„ë³´ë©´ ì •í™•ë„ê°€ ì˜¬ë¼ê°€ìš”.")
            else:
                st.markdown("### ê³µí†µ ì›ì¸ TOP (ìµœëŒ€ 3)")
                for i, c in enumerate(top_causes, start=1):
                    with st.container(border=True):
                        st.markdown(f"### {i}) {c.get('cause','(ì›ì¸)')}")
                        st.write(c.get("summary", ""))

                        st.markdown("**ì‹¤í–‰ ê°€ëŠ¥í•œ ê°œì„  ì¡°ì–¸(í˜„ì‹¤ ë²„ì „)**")
                        for tip in (c.get("actionable_advice") or [])[:6]:
                            st.write(f"- {tip}")

                        creative = c.get("creative_advice_when_repeated_2w") or []
                        if creative:
                            st.markdown("**2ì£¼ ì´ìƒ ë°˜ë³µ ì‹œ: ì™„ì „íˆ ë‹¤ë¥¸ ê°ë„ì˜ ëŒ€ì•ˆ(ì°½ì˜ ë²„ì „)**")
                            for tip in creative[:6]:
                                st.write(f"- {tip}")

                st.caption(result.get("tone_note", ""))

            with st.expander("ğŸ” ì´ë²ˆ ë¶„ì„ì— ì‚¬ìš©ëœ ë°ì´í„° ë³´ê¸°", expanded=False):
                st.dataframe(pd.DataFrame(items), use_container_width=True, hide_index=True)

    # -------------------------
    # Tab 4: Manage
    # -------------------------
    with tab_manage:
        st.subheader("ê´€ë¦¬")
        subtab_plans, subtab_causes, subtab_reminder, subtab_fix = st.tabs(
            ["ê³„íš", "ì›ì¸ ì¹´í…Œê³ ë¦¬", "ì•Œë¦¼(ë¦¬ë§ˆì¸ë”)", "ë°ì´í„° ì •ë¦¬/ìˆ˜ì •"]
        )

        with subtab_plans:
            col1, col2 = st.columns([2, 3])
            with col1:
                st.markdown("#### ìƒˆ ê³„íš ì¶”ê°€")
                new_title = st.text_input("ê³„íš/ìŠµê´€ ì´ë¦„", placeholder="ì˜ˆ: ì˜ì–´ ë‹¨ì–´ 20ê°œ / ìš´ë™ 20ë¶„", key="new_plan")
                if st.button("ì¶”ê°€", key="add_plan_btn"):
                    if not new_title.strip():
                        st.error("ê³„íš ì´ë¦„ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
                    else:
                        add_plan(new_title.strip())
                        st.success("ì¶”ê°€ ì™„ë£Œ!")
                        st.rerun()

            with col2:
                st.markdown("#### ë‚´ ê³„íš ëª©ë¡")
                plans_df = list_plans(active_only=False)
                if plans_df.empty:
                    st.info("ì•„ì§ ê³„íšì´ ì—†ì–´ìš”. ì™¼ìª½ì—ì„œ ì¶”ê°€í•´ ì£¼ì„¸ìš”.")
                else:
                    for _, r in plans_df.iterrows():
                        with st.container(border=True):
                            a, b, c = st.columns([4, 2, 2])
                            with a:
                                st.markdown(f"**{r['title']}**")
                                st.caption(f"ìƒì„±: {r['created_at']}")
                            with b:
                                active = bool(r["active"])
                                st.write("ìƒíƒœ:", "í™œì„± âœ…" if active else "ë¹„í™œì„± â›”")
                            with c:
                                if active:
                                    if st.button("ë¹„í™œì„±í™”", key=f"deact_{r['id']}"):
                                        set_plan_active(int(r["id"]), False)
                                        st.rerun()
                                else:
                                    if st.button("í™œì„±í™”", key=f"act_{r['id']}"):
                                        set_plan_active(int(r["id"]), True)
                                        st.rerun()

        with subtab_causes:
            st.markdown("#### ì›ì¸ ì¹´í…Œê³ ë¦¬ ëª©ë¡(ë¶„ë¥˜ ê¸°ì¤€)")
            causes_df = list_causes(active_only=False)
            for _, r in causes_df.iterrows():
                with st.container(border=True):
                    c1, c2, c3 = st.columns([3, 5, 2])
                    with c1:
                        st.markdown(f"**{r['name']}**")
                        st.caption("í™œì„± âœ…" if int(r["active"]) == 1 else "ë¹„í™œì„± â›”")
                    with c2:
                        st.write(r["description"] or "")
                        try:
                            kws = json.loads(r["keywords"] or "[]")
                        except Exception:
                            kws = []
                        if kws:
                            st.caption("í‚¤ì›Œë“œ: " + ", ".join(kws))
                    with c3:
                        if int(r["active"]) == 1:
                            if st.button("ë¹„í™œì„±í™”", key=f"cause_off_{r['id']}"):
                                set_cause_active(int(r["id"]), False)
                                st.rerun()
                        else:
                            if st.button("í™œì„±í™”", key=f"cause_on_{r['id']}"):
                                set_cause_active(int(r["id"]), True)
                                st.rerun()

            st.markdown("---")
            st.markdown("#### ìƒˆ ì›ì¸ ì¹´í…Œê³ ë¦¬ ì¶”ê°€")
            name = st.text_input("ì´ë¦„", placeholder="ì˜ˆ: ì¥ì†Œ/ë„êµ¬ ë¬¸ì œ", key="cause_new_name")
            desc = st.text_area("ì„¤ëª…", placeholder="ì´ ì¹´í…Œê³ ë¦¬ê°€ í¬í•¨í•˜ëŠ” ì‹¤íŒ¨ì˜ ê³µí†µ íŠ¹ì§•", key="cause_new_desc")
            kws_raw = st.text_input("í‚¤ì›Œë“œ(ì‰¼í‘œë¡œ êµ¬ë¶„)", placeholder="ì˜ˆ: ì¥ì†Œ, ì¹´í˜, ë…¸íŠ¸ë¶, ì¤€ë¹„ë¬¼", key="cause_new_kws")
            if st.button("ì›ì¸ ì¶”ê°€", key="cause_add_btn"):
                if not name.strip():
                    st.error("ì´ë¦„ì€ í•„ìˆ˜ì˜ˆìš”.")
                else:
                    kws = [x.strip() for x in kws_raw.split(",") if x.strip()]
                    try:
                        add_cause(name, desc, kws)
                        st.success("ì¶”ê°€ ì™„ë£Œ!")
                        st.rerun()
                    except sqlite3.IntegrityError:
                        st.error("ì´ë¯¸ ê°™ì€ ì´ë¦„ì˜ ì›ì¸ì´ ìˆì–´ìš”. ì´ë¦„ì„ ë°”ê¿”ì£¼ì„¸ìš”.")

        with subtab_reminder:
            st.markdown("#### ë¦¬ë§ˆì¸ë” ì„¤ì •")
            enabled = st.toggle("ë¦¬ë§ˆì¸ë” ì¼œê¸°", value=reminder_enabled, key="rem_en")
            rt = st.text_input("ë¦¬ë§ˆì¸ë” ì‹œê°„(HH:MM)", value=get_setting("reminder_time", "21:30"), key="rem_time")
            wm = st.number_input("í‘œì‹œ í—ˆìš© ì˜¤ì°¨(ë¶„)", min_value=1, max_value=120,
                                 value=int(get_setting("reminder_window_min", "15")), key="rem_win")
            ps = st.number_input("ì•± ë‚´ ì²´í¬ ì£¼ê¸°(ì´ˆ)", min_value=10, max_value=600,
                                 value=int(get_setting("reminder_poll_sec", "60")), key="rem_poll")

            if st.button("ì„¤ì • ì €ì¥", key="rem_save"):
                upsert_setting("reminder_enabled", "true" if enabled else "false")
                upsert_setting("reminder_time", rt.strip())
                upsert_setting("reminder_window_min", str(int(wm)))
                upsert_setting("reminder_poll_sec", str(int(ps)))
                st.success("ì €ì¥í–ˆì–´ìš”. (ì•±ì´ ì¼œì ¸ ìˆì„ ë•Œ ì„¤ì • ì‹œê°„ì— ë°°ë„ˆê°€ ë– ìš”)")
                st.rerun()

            st.markdown("---")
            st.markdown("#### ìº˜ë¦°ë”ë¡œ ë¦¬ë§ˆì¸ë” ë°›ê¸°(.ics)")
            t = parse_hhmm(rt)
            ics = build_daily_ics(t)
            st.download_button(
                "ğŸ“¥ ë§¤ì¼ ë¦¬ë§ˆì¸ë” .ics ë‹¤ìš´ë¡œë“œ",
                data=ics.encode("utf-8"),
                file_name="failog_daily_reminder.ics",
                mime="text/calendar",
            )
            st.caption("ë‹¤ìš´ë¡œë“œ í›„ ìº˜ë¦°ë”ì— ê°€ì ¸ì˜¤ê¸°(import) í•˜ë©´, ì•±ì„ ì•ˆ ì¼œë„ OS/ìº˜ë¦°ë” ì•Œë¦¼ì„ ë°›ì„ ìˆ˜ ìˆì–´ìš”.")

        with subtab_fix:
            st.markdown("#### ì‹¤íŒ¨ ê¸°ë¡ì˜ ì›ì¸ ìˆ˜ì •(ì •í™•ë„ ê°œì„ )")
            d1 = st.date_input("ì‹œì‘ì¼", value=today_local() - timedelta(days=14), key="fix_s")
            d2 = st.date_input("ì¢…ë£Œì¼", value=today_local(), key="fix_e")
            df = get_failures(d1, d2)
            if df.empty:
                st.info("ì„ íƒí•œ ê¸°ê°„ì— ì‹¤íŒ¨ ê¸°ë¡ì´ ì—†ì–´ìš”.")
            else:
                df = df.copy()
                df["cause_name"] = df["cause_name"].fillna("ê¸°íƒ€(ëª…í™•í™” í•„ìš”)")
                st.dataframe(
                    df[["id", "log_date", "plan_title", "reason", "cause_name", "cause_source", "cause_confidence"]],
                    use_container_width=True,
                    hide_index=True,
                )

                st.markdown("ì›ì¸ ìˆ˜ì •:")
                causes_df = list_causes(active_only=True)
                cause_names = causes_df["name"].tolist()

                target_id = st.number_input(
                    "ìˆ˜ì •í•  log id",
                    min_value=int(df["id"].min()),
                    max_value=int(df["id"].max()),
                    value=int(df["id"].min()),
                    step=1,
                )
                new_cause = st.selectbox("ìƒˆ ì›ì¸", options=cause_names, index=0)

                if st.button("ì›ì¸ ì—…ë°ì´íŠ¸", key="fix_update"):
                    conn = get_conn()
                    conn.execute(
                        """
                        UPDATE daily_logs
                        SET cause_name=?, cause_source='user', cause_confidence=1.0, cause_updated_at=?, updated_at=?
                        WHERE id=?
                        """,
                        (new_cause, now_iso(), now_iso(), int(target_id)),
                    )
                    conn.commit()
                    conn.close()
                    st.success("ì—…ë°ì´íŠ¸ ì™„ë£Œ! ë‹¤ìŒ ë¶„ì„ë¶€í„° ë” ì •í™•í•´ì ¸ìš”.")
                    st.rerun()

    st.markdown("---")
    st.caption(f"Â© failog â€¢ Timezone hint: {DEFAULT_TZ} â€¢ DB: {DB_PATH}")


if __name__ == "__main__":
    main()
