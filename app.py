# failog_app.py
# Streamlit app: failog (ê³„íš ì‹¤íŒ¨ ê¸°ë¡ â†’ ì›ì¸ ë¶„ë¥˜(ì €ì¥) â†’ ì£¼ê°„ ë¦¬í¬íŠ¸/íŠ¸ë Œë“œ/ë¦¬ë§ˆì¸ë”/ì½”ì¹­)
#
# í¬í•¨ ê¸°ëŠ¥
# 1) ë°ì¼ë¦¬ ì²´í¬(ì„±ê³µ/ì‹¤íŒ¨ + ì‹¤íŒ¨ ì´ìœ  + ì›ì¸ ì¹´í…Œê³ ë¦¬ ì €ì¥)
# 2) ì›ì¸ ì¹´í…Œê³ ë¦¬ë³„ íŒŒì´ì°¨íŠ¸/íŠ¸ë Œë“œ(ì£¼ì°¨ë³„/ì¼ìë³„)
# 3) ìŠµê´€/ëª©í‘œë³„ ì£¼ê°„ ë¦¬í¬íŠ¸(ì„±ê³µë¥ , ì‹¤íŒ¨ Top ì›ì¸, ë°˜ë³µ ì‹¤íŒ¨ ê°ì§€)
# 4) ì•Œë¦¼(ë¦¬ë§ˆì¸ë”)
#    - ì•±ì´ ì—´ë ¤ ìˆì„ ë•Œ: ì„¤ì •í•œ ì‹œê°„ëŒ€ì— "ë¯¸ì²´í¬/ëŒ€ê¸°" í•­ëª©ì´ ìˆìœ¼ë©´ í™”ë©´ í† ìŠ¤íŠ¸/ë°°ë„ˆ
#    - OS/ìº˜ë¦°ë”ìš©: ë§¤ì¼ ë¦¬ë§ˆì¸ë” .ics íŒŒì¼ ë‹¤ìš´ë¡œë“œ(ê°€ì¥ í˜„ì‹¤ì ì¸ í¬ë¡œìŠ¤í”Œë«í¼)
# 5) ì½”ì¹­ ìƒì„±(ê³µí†µ ì›ì¸ 3ê°œ ì´ë‚´ + ì‹¤í–‰ê°€ëŠ¥ ì¡°ì–¸ + 2ì£¼ ì´ìƒ ë°˜ë³µ ì›ì¸ì— ì°½ì˜ ëŒ€ì•ˆ)
#    - OpenAI í‚¤ê°€ ìˆìœ¼ë©´ LLMìœ¼ë¡œ ë” ì„¬ì„¸í•˜ê²Œ
#    - ì—†ìœ¼ë©´ ë¡œì»¬ ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ ë™ì‘
#
# ì‹¤í–‰:
#   pip install streamlit pandas openai streamlit-autorefresh
#   export OPENAI_API_KEY="..."
#   streamlit run failog_app.py
#
# NOTE: Streamlit ë¦¬ë§ˆì¸ë”ëŠ” "ì•±ì´ ì¼œì ¸ ìˆì„ ë•Œ"ë§Œ ë™ì‘í•©ë‹ˆë‹¤.
#       ì§€ì† í‘¸ì‹œ ì•Œë¦¼ì€ ë³„ë„ ë°±ì—”ë“œ/ëª¨ë°”ì¼/ë¸Œë¼ìš°ì € í‘¸ì‹œê°€ í•„ìš”í•˜ë¯€ë¡œ, ì—¬ê¸°ì„œëŠ” .ics ì œê³µì´ ê°€ì¥ ì‹¤ìš©ì ì…ë‹ˆë‹¤.

import os
import re
import json
import sqlite3
from datetime import datetime, date, timedelta, time
from typing import Optional, Dict, Any, List, Tuple

import pandas as pd
import streamlit as st

# Optional: autorefresh for reminder polling
try:
    from streamlit_autorefresh import st_autorefresh
except Exception:
    st_autorefresh = None

# Optional: OpenAI
try:
    from openai import OpenAI
except Exception:
    OpenAI = None


# -----------------------------
# Config
# -----------------------------
APP_TITLE = "failog â€” ì‹¤íŒ¨ë¥¼ ì‹¤í–‰ ì „ëµìœ¼ë¡œ ë°”ê¿”ì£¼ëŠ” ì½”ì¹­"
DB_PATH = os.environ.get("FAILOG_DB_PATH", "failog.db")
DEFAULT_TZ = "Asia/Seoul"  # UI ì°¸ê³ ìš©(ì„œë²„ ì‹œê°„ì€ í™˜ê²½ì— ì˜ì¡´)


# -----------------------------
# Utilities
# -----------------------------
def now_iso():
    return datetime.now().isoformat(timespec="seconds")


def today_local() -> date:
    # Streamlit ì„œë²„ê°€ ë¡œì»¬ íƒ€ì„ì¡´ì´ ì•„ë‹ ìˆ˜ë„ ìˆì§€ë§Œ, ì‚¬ìš©ì ê¸°ì¤€ ë‹¨ìˆœ ì‚¬ìš©.
    return date.today()


def normalize_text(text: str) -> str:
    t = (text or "").strip().lower()
    t = re.sub(r"\s+", " ", t)
    t = re.sub(r"[^\w\sê°€-í£]", "", t)
    return t


def week_start(d: date) -> date:
    # Monday start
    return d - timedelta(days=d.weekday())


def to_date(s: str) -> date:
    return datetime.fromisoformat(s).date()


# -----------------------------
# DB Layer (SQLite) + Migrations
# -----------------------------
def get_conn():
    conn = sqlite3.connect(DB_PATH, check_same_thread=False)
    conn.execute("PRAGMA foreign_keys = ON;")
    return conn


def table_columns(conn, table: str) -> List[str]:
    cur = conn.cursor()
    cur.execute(f"PRAGMA table_info({table});")
    return [r[1] for r in cur.fetchall()]


def ensure_column(conn, table: str, col: str, ddl_type: str, default_sql: Optional[str] = None):
    cols = table_columns(conn, table)
    if col in cols:
        return
    dflt = f" DEFAULT {default_sql}" if default_sql is not None else ""
    conn.execute(f"ALTER TABLE {table} ADD COLUMN {col} {ddl_type}{dflt};")


def init_db():
    conn = get_conn()
    cur = conn.cursor()

    # plans
    cur.execute(
        """
        CREATE TABLE IF NOT EXISTS plans (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            title TEXT NOT NULL,
            active INTEGER NOT NULL DEFAULT 1,
            created_at TEXT NOT NULL
        );
        """
    )

    # daily logs (base)
    cur.execute(
        """
        CREATE TABLE IF NOT EXISTS daily_logs (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            log_date TEXT NOT NULL,
            plan_id INTEGER NOT NULL,
            status TEXT NOT NULL CHECK(status IN ('pending','success','fail')),
            reason TEXT,
            created_at TEXT NOT NULL,
            updated_at TEXT NOT NULL,
            UNIQUE(log_date, plan_id),
            FOREIGN KEY(plan_id) REFERENCES plans(id) ON DELETE CASCADE
        );
        """
    )

    # taxonomy table for causes (editable)
    cur.execute(
        """
        CREATE TABLE IF NOT EXISTS cause_taxonomy (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            name TEXT NOT NULL UNIQUE,
            description TEXT,
            keywords TEXT, -- JSON array string
            active INTEGER NOT NULL DEFAULT 1,
            created_at TEXT NOT NULL,
            updated_at TEXT NOT NULL
        );
        """
    )

    # settings
    cur.execute(
        """
        CREATE TABLE IF NOT EXISTS settings (
            key TEXT PRIMARY KEY,
            value TEXT NOT NULL,
            updated_at TEXT NOT NULL
        );
        """
    )

    conn.commit()

    # migrations for daily_logs: store cause classification
    ensure_column(conn, "daily_logs", "cause_name", "TEXT", None)
    ensure_column(conn, "daily_logs", "cause_source", "TEXT", "'none'")  # user|ai|rule|none
    ensure_column(conn, "daily_logs", "cause_confidence", "REAL", "0.0")  # 0~1
    ensure_column(conn, "daily_logs", "cause_updated_at", "TEXT", None)

    conn.commit()

    # seed taxonomy if empty
    n = cur.execute("SELECT COUNT(*) FROM cause_taxonomy;").fetchone()[0]
    if n == 0:
        seed = [
            ("ì‹œê°„/ì¼ì •", "íšŒì˜/ì•¼ê·¼/ì´ë™/ë§ˆê° ë“±ìœ¼ë¡œ ì‹œê°„ì´ ë°€ë¦¬ê±°ë‚˜ ê³„íš íƒ€ì´ë°ì´ ê¹¨ì§„ ê²½ìš°", ["ì‹œê°„", "ì•¼ê·¼", "íšŒì˜", "ì¼ì •", "ì•½ì†", "ë§ˆê°", "ì´ë™", "ì¶œê·¼", "ëŠ¦"]),
            ("ì—ë„ˆì§€/ì»¨ë””ì…˜", "í”¼ë¡œ/ìˆ˜ë©´/ì»¨ë””ì…˜ ì €í•˜ë¡œ ì‹¤í–‰ ì—ë„ˆì§€ê°€ ë¶€ì¡±í•œ ê²½ìš°", ["í”¼ê³¤", "ì¡¸ë¦¼", "ì ", "ì»¨ë””ì…˜", "ì§€ì¹¨", "ì•„íŒŒ", "ë‘í†µ"]),
            ("í™˜ê²½/ë°©í•´ìš”ì¸", "í°/SNS/ìœ íŠœë¸Œ/ì†ŒìŒ/ì¹¨ëŒ€ ë“± ë°©í•´ìê·¹ì´ ê°•í–ˆë˜ ê²½ìš°", ["í°", "íœ´ëŒ€í°", "ìœ íŠœë¸Œ", "sns", "ë°©í•´", "ì†ŒìŒ", "ì¹¨ëŒ€", "ê²Œì„", "ë„·í”Œ"]),
            ("ê³„íš/ì„¤ê³„", "ëª©í‘œê°€ ê³¼ë„í•˜ê±°ë‚˜ êµ¬ì²´ì„±ì´ ë¶€ì¡±í•´ì„œ ì‹œì‘/ìœ ì§€ê°€ ì–´ë ¤ì› ë˜ ê²½ìš°", ["ë„ˆë¬´", "ê³¼í•˜ê²Œ", "ë¬´ë¦¬", "ê³„íš", "ëª©í‘œ", "ë¶„ëŸ‰", "ìš°ì„ ìˆœìœ„", "ì •ë¦¬"]),
            ("ë™ê¸°/ì˜ë¯¸", "ì˜ìš• ì €í•˜/ê·€ì°®ìŒ/ë¯¸ë£¨ê¸°/ì˜ë¯¸ ë¶€ì¡±ìœ¼ë¡œ ì‹¤í–‰ì´ ëŠê¸´ ê²½ìš°", ["ì˜ìš•", "ë™ê¸°", "ê·€ì°®", "í•˜ê¸°ì‹«", "ì˜ë¯¸", "ë¯¸ë£¸", "ë¯¸ë£¨"]),
            ("ê¸°íƒ€(ëª…í™•í™” í•„ìš”)", "ë¶„ë¥˜ê°€ ì• ë§¤í•˜ê±°ë‚˜ ì´ìœ ê°€ ë¶ˆëª…í™•í•œ ê²½ìš°(ë‹¤ìŒ ê¸°ë¡ ë•Œ í•œ ë¬¸ì¥ ë” êµ¬ì²´í™”)", []),
        ]
        for name, desc, kws in seed:
            cur.execute(
                """
                INSERT INTO cause_taxonomy (name, description, keywords, active, created_at, updated_at)
                VALUES (?, ?, ?, 1, ?, ?)
                """,
                (name, desc, json.dumps(kws, ensure_ascii=False), now_iso(), now_iso()),
            )
        conn.commit()

    # seed settings defaults
    def set_default(key: str, value: str):
        cur.execute(
            "INSERT OR IGNORE INTO settings (key, value, updated_at) VALUES (?, ?, ?)",
            (key, value, now_iso()),
        )

    set_default("reminder_enabled", "true")
    set_default("reminder_time", "21:30")  # HH:MM
    set_default("reminder_window_min", "15")  # minutes
    set_default("reminder_poll_sec", "60")  # seconds
    conn.commit()

    conn.close()


# -----------------------------
# CRUD
# -----------------------------
def add_plan(title: str):
    conn = get_conn()
    conn.execute(
        "INSERT INTO plans (title, active, created_at) VALUES (?, 1, ?)",
        (title.strip(), now_iso()),
    )
    conn.commit()
    conn.close()


def set_plan_active(plan_id: int, active: bool):
    conn = get_conn()
    conn.execute("UPDATE plans SET active=? WHERE id=?", (1 if active else 0, plan_id))
    conn.commit()
    conn.close()


def list_plans(active_only: bool = False) -> pd.DataFrame:
    conn = get_conn()
    q = "SELECT id, title, active, created_at FROM plans"
    if active_only:
        q += " WHERE active=1"
    q += " ORDER BY id DESC"
    df = pd.read_sql_query(q, conn)
    conn.close()
    return df


def ensure_daily_rows(log_date: date):
    conn = get_conn()
    cur = conn.cursor()
    plans = cur.execute("SELECT id FROM plans WHERE active=1").fetchall()
    for (pid,) in plans:
        cur.execute(
            """
            INSERT OR IGNORE INTO daily_logs
              (log_date, plan_id, status, reason, created_at, updated_at, cause_name, cause_source, cause_confidence, cause_updated_at)
            VALUES (?, ?, 'pending', NULL, ?, ?, NULL, 'none', 0.0, NULL)
            """,
            (log_date.isoformat(), pid, now_iso(), now_iso()),
        )
    conn.commit()
    conn.close()


def get_daily_logs(log_date: date) -> pd.DataFrame:
    conn = get_conn()
    df = pd.read_sql_query(
        """
        SELECT dl.id, dl.log_date, dl.plan_id, p.title AS plan_title,
               dl.status, dl.reason,
               dl.cause_name, dl.cause_source, dl.cause_confidence,
               dl.updated_at
        FROM daily_logs dl
        JOIN plans p ON p.id = dl.plan_id
        WHERE dl.log_date = ?
        ORDER BY p.id DESC
        """,
        conn,
        params=(log_date.isoformat(),),
    )
    conn.close()
    return df


def update_log_success(log_id: int):
    conn = get_conn()
    conn.execute(
        """
        UPDATE daily_logs
        SET status='success', reason=NULL,
            cause_name=NULL, cause_source='none', cause_confidence=0.0, cause_updated_at=NULL,
            updated_at=?
        WHERE id=?
        """,
        (now_iso(), log_id),
    )
    conn.commit()
    conn.close()


def update_log_fail(
    log_id: int,
    reason: str,
    cause_name: Optional[str],
    cause_source: str,
    cause_confidence: float,
):
    conn = get_conn()
    conn.execute(
        """
        UPDATE daily_logs
        SET status='fail', reason=?,
            cause_name=?, cause_source=?, cause_confidence=?, cause_updated_at=?,
            updated_at=?
        WHERE id=?
        """,
        (
            reason.strip() if reason else "ì´ìœ  ë¯¸ê¸°ë¡",
            cause_name,
            cause_source,
            float(cause_confidence),
            now_iso(),
            now_iso(),
            log_id,
        ),
    )
    conn.commit()
    conn.close()


def update_log_pending(log_id: int):
    conn = get_conn()
    conn.execute(
        """
        UPDATE daily_logs
        SET status='pending', reason=NULL,
            cause_name=NULL, cause_source='none', cause_confidence=0.0, cause_updated_at=NULL,
            updated_at=?
        WHERE id=?
        """,
        (now_iso(), log_id),
    )
    conn.commit()
    conn.close()


def get_failures(start_date: date, end_date: date) -> pd.DataFrame:
    conn = get_conn()
    df = pd.read_sql_query(
        """
        SELECT dl.id, dl.log_date, dl.plan_id, p.title AS plan_title,
               dl.reason, dl.cause_name, dl.cause_source, dl.cause_confidence
        FROM daily_logs dl
        JOIN plans p ON p.id = dl.plan_id
        WHERE dl.status='fail'
          AND dl.log_date BETWEEN ? AND ?
        ORDER BY dl.log_date ASC
        """,
        conn,
        params=(start_date.isoformat(), end_date.isoformat()),
    )
    conn.close()
    return df


def get_logs_range(start_date: date, end_date: date, active_only: bool = False) -> pd.DataFrame:
    conn = get_conn()
    where_active = "AND p.active=1" if active_only else ""
    df = pd.read_sql_query(
        f"""
        SELECT dl.id, dl.log_date, dl.plan_id, p.title AS plan_title, p.active,
               dl.status, dl.reason,
               dl.cause_name, dl.cause_source, dl.cause_confidence
        FROM daily_logs dl
        JOIN plans p ON p.id = dl.plan_id
        WHERE dl.log_date BETWEEN ? AND ?
        {where_active}
        ORDER BY dl.log_date ASC, p.id DESC
        """,
        conn,
        params=(start_date.isoformat(), end_date.isoformat()),
    )
    conn.close()
    return df


# -----------------------------
# Taxonomy + Settings
# -----------------------------
def list_causes(active_only: bool = True) -> pd.DataFrame:
    conn = get_conn()
    q = "SELECT id, name, description, keywords, active, updated_at FROM cause_taxonomy"
    if active_only:
        q += " WHERE active=1"
    q += " ORDER BY id ASC"
    df = pd.read_sql_query(q, conn)
    conn.close()
    return df


def upsert_setting(key: str, value: str):
    conn = get_conn()
    conn.execute(
        """
        INSERT INTO settings (key, value, updated_at)
        VALUES (?, ?, ?)
        ON CONFLICT(key) DO UPDATE SET value=excluded.value, updated_at=excluded.updated_at
        """,
        (key, value, now_iso()),
    )
    conn.commit()
    conn.close()


def get_setting(key: str, default: str) -> str:
    conn = get_conn()
    cur = conn.cursor()
    row = cur.execute("SELECT value FROM settings WHERE key=?", (key,)).fetchone()
    conn.close()
    return row[0] if row else default


def add_cause(name: str, description: str, keywords_list: List[str]):
    conn = get_conn()
    conn.execute(
        """
        INSERT INTO cause_taxonomy (name, description, keywords, active, created_at, updated_at)
        VALUES (?, ?, ?, 1, ?, ?)
        """,
        (name.strip(), description.strip(), json.dumps(keywords_list, ensure_ascii=False), now_iso(), now_iso()),
    )
    conn.commit()
    conn.close()


def set_cause_active(cause_id: int, active: bool):
    conn = get_conn()
    conn.execute(
        "UPDATE cause_taxonomy SET active=?, updated_at=? WHERE id=?",
        (1 if active else 0, now_iso(), cause_id),
    )
    conn.commit()
    conn.close()


# -----------------------------
# Classification (OpenAI / Fallback keyword)
# -----------------------------
def fallback_classify_reason(reason: str, causes_df: pd.DataFrame) -> Tuple[str, float, str]:
    """Return (cause_name, confidence, source)."""
    r = (reason or "").lower()
    best = ("ê¸°íƒ€(ëª…í™•í™” í•„ìš”)", 0.35)
    for _, row in causes_df.iterrows():
        name = row["name"]
        try:
            kws = json.loads(row["keywords"] or "[]")
        except Exception:
            kws = []
        if not kws:
            continue
        hits = sum(1 for kw in kws if kw and kw.lower() in r)
        if hits > 0:
            conf = min(0.55 + 0.1 * hits, 0.9)
            if conf > best[1]:
                best = (name, conf)
    return best[0], best[1], "rule"


def openai_classify_reason(reason: str, cause_names: List[str]) -> Tuple[str, float, str]:
    api_key = os.environ.get("OPENAI_API_KEY", "").strip()
    if not api_key or OpenAI is None:
        raise RuntimeError("OpenAI not configured.")
    client = OpenAI(api_key=api_key)
    model = os.environ.get("FAILOG_OPENAI_MODEL", "gpt-4o-mini")

    prompt = f"""
ë„ˆëŠ” ì‚¬ìš©ìì˜ 'ê³„íš ì‹¤íŒ¨ ì´ìœ 'ë¥¼ ì•„ë˜ ì›ì¸ ì¹´í…Œê³ ë¦¬ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•´.
ì¹´í…Œê³ ë¦¬ ëª©ë¡: {json.dumps(cause_names, ensure_ascii=False)}

ì…ë ¥ ì‹¤íŒ¨ ì´ìœ :
{reason}

ê·œì¹™:
- ë°˜ë“œì‹œ ëª©ë¡ ì¤‘ í•˜ë‚˜ë§Œ ì„ íƒ
- ì¶œë ¥ì€ JSONë§Œ
í˜•ì‹:
{{"cause":"...", "confidence":0.0}}
confidenceëŠ” 0~1 (í™•ì‹ ì´ ë‚®ìœ¼ë©´ 0.4~0.6)
""".strip()

    resp = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": "Return valid JSON only."},
            {"role": "user", "content": prompt},
        ],
        temperature=0.2,
    )
    text = resp.choices[0].message.content.strip()
    try:
        obj = json.loads(text)
    except json.JSONDecodeError:
        m = re.search(r"\{.*\}", text, flags=re.DOTALL)
        if not m:
            raise
        obj = json.loads(m.group(0))

    cause = obj.get("cause", "").strip()
    conf = float(obj.get("confidence", 0.5))
    if cause not in cause_names:
        # safety: snap to ê¸°íƒ€
        cause = "ê¸°íƒ€(ëª…í™•í™” í•„ìš”)" if "ê¸°íƒ€(ëª…í™•í™” í•„ìš”)" in cause_names else cause_names[-1]
        conf = min(conf, 0.55)
    conf = max(0.0, min(1.0, conf))
    return cause, conf, "ai"


def classify_reason(reason: str, prefer_openai: bool = True) -> Tuple[str, float, str]:
    causes_df = list_causes(active_only=True)
    cause_names = causes_df["name"].tolist()
    if not reason.strip():
        # ë¹ˆ ì´ìœ ëŠ” ê¸°íƒ€ë¡œ
        return ("ê¸°íƒ€(ëª…í™•í™” í•„ìš”)" if "ê¸°íƒ€(ëª…í™•í™” í•„ìš”)" in cause_names else cause_names[-1], 0.35, "rule")

    if prefer_openai:
        try:
            return openai_classify_reason(reason, cause_names)
        except Exception:
            pass
    return fallback_classify_reason(reason, causes_df)


# -----------------------------
# Repeated detection (>=14 days) by CAUSE (plan_id + cause_name)
# -----------------------------
def detect_repeated_causes_2w(failures_df: pd.DataFrame) -> Dict[Tuple[int, str], bool]:
    """
    Returns flags for (plan_id, cause_name) if failures span >= 14 days within the analysis window.
    """
    if failures_df.empty:
        return {}
    df = failures_df.copy()
    df["log_date"] = pd.to_datetime(df["log_date"]).dt.date
    df["cause_name"] = df["cause_name"].fillna("ê¸°íƒ€(ëª…í™•í™” í•„ìš”)")
    flags: Dict[Tuple[int, str], bool] = {}
    for (pid, cause), g in df.groupby(["plan_id", "cause_name"]):
        dates = sorted(g["log_date"].tolist())
        if len(dates) >= 2 and (dates[-1] - dates[0]).days >= 14:
            flags[(int(pid), str(cause))] = True
    return flags


# -----------------------------
# Coaching Engine
# -----------------------------
COACH_SCHEMA_HINT = """
ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥í•´. (ì„¤ëª…/ë§ˆí¬ë‹¤ìš´ ê¸ˆì§€)
í˜•ì‹:
{
  "top_causes": [
    {
      "cause": "ì›ì¸ ì¹´í…Œê³ ë¦¬ ì´ë¦„(ì§§ê²Œ)",
      "summary": "ì™œ ì´ê²Œ ê³µí†µ ì›ì¸ì¸ì§€ 2~3ë¬¸ì¥",
      "actionable_advice": ["í˜„ì‹¤ì  ì¡°ì–¸ 1", "í˜„ì‹¤ì  ì¡°ì–¸ 2", "í˜„ì‹¤ì  ì¡°ì–¸ 3"],
      "creative_advice_when_repeated_2w": ["(í•´ë‹¹ ì›ì¸ì´ 2ì£¼ ì´ìƒ ë°˜ë³µëœ í•­ëª©ì´ ìˆì„ ë•Œë§Œ) ì°½ì˜ì  ì¡°ì–¸ 1", "..."]
    }
  ],
  "tone_note": "ì „ì²´ í†¤ì´ ë¹„ë‚œ ì—†ì´ ì½”ì¹­ ì¤‘ì‹¬ì¸ì§€ ì ê²€í•˜ëŠ” í•œ ë¬¸ì¥"
}
ê·œì¹™:
- top_causesëŠ” ìµœëŒ€ 3ê°œ
- actionable_adviceëŠ” 'ì§€ê¸ˆ ë‹¹ì¥ ì‹¤í–‰' ê°€ëŠ¥í•œ ìˆ˜ì¤€(ì‘ê³  êµ¬ì²´ì )ìœ¼ë¡œ
- 'ë¹„ë‚œ/ìì±… ìœ ë„' í‘œí˜„ ê¸ˆì§€
- 2ì£¼ ì´ìƒ ë°˜ë³µ(repeated_2w=true)ëœ ì›ì¸ì´ ìˆìœ¼ë©´, í•´ë‹¹ ì›ì¸ì— creative_advice_when_repeated_2wë¥¼ ë°˜ë“œì‹œ í¬í•¨
- ë°˜ë³µ ì›ì¸ì´ ì—†ìœ¼ë©´ creative_advice_when_repeated_2wëŠ” ë¹ˆ ë°°ì—´([])ë¡œ
"""


def build_coach_prompt(items: List[Dict[str, Any]]) -> str:
    return f"""
ë„ˆëŠ” 'ì‹¤íŒ¨ ê¸°ë¡ì„ ì‹¤í–‰ ì „ëµìœ¼ë¡œ ë°”ê¾¸ëŠ”' ì½”ì¹­ AIì•¼.
ì‚¬ìš©ìê°€ ì ì€ "ì‹¤íŒ¨ ì´ìœ "ì™€ "ì›ì¸ ì¹´í…Œê³ ë¦¬" ë°ì´í„°ë¥¼ ë³´ê³  ê³µí†µ ì›ì¸ì„ ìµœëŒ€ 3ê°€ì§€ë¡œ ë¬¶ê³ ,
ê° ì›ì¸ì— ëŒ€í•´ ì‹¤í–‰ ê°€ëŠ¥í•˜ê³  í˜„ì‹¤ì ì¸ ê°œì„  ì¡°ì–¸ì„ ì œì‹œí•´.
ì¶”ê°€ ê·œì¹™: ë§Œì•½ repeated_2w=true ì¸ ì›ì¸(ê°™ì€ ì›ì¸ì´ 2ì£¼ ì´ìƒ ë°˜ë³µ)ì´ ìˆë‹¤ë©´,
ê·¸ ì›ì¸ì— ëŒ€í•´ ê¸°ì¡´ ì¡°ì–¸ê³¼ ê²°ì´ ë‹¤ë¥¸ "ì°½ì˜ì ì¸ ëŒ€ì•ˆ ì¡°ì–¸"ë„ ì œì‹œí•´.
í†¤ì€ ì ˆëŒ€ ë¹„ë‚œí•˜ì§€ ë§ê³ , ì½”ì¹­/ê²©ë ¤ ì¤‘ì‹¬ìœ¼ë¡œ.

ì…ë ¥ ë°ì´í„°:
{json.dumps(items, ensure_ascii=False, indent=2)}

{COACH_SCHEMA_HINT}
""".strip()


def openai_coach(items: List[Dict[str, Any]]) -> Dict[str, Any]:
    api_key = os.environ.get("OPENAI_API_KEY", "").strip()
    if not api_key or OpenAI is None:
        raise RuntimeError("OpenAI not configured.")
    client = OpenAI(api_key=api_key)
    model = os.environ.get("FAILOG_OPENAI_MODEL", "gpt-4o-mini")

    resp = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": "You are a supportive coaching assistant. Output must be valid JSON only."},
            {"role": "user", "content": build_coach_prompt(items)},
        ],
        temperature=0.7,
    )
    text = resp.choices[0].message.content.strip()
    try:
        return json.loads(text)
    except json.JSONDecodeError:
        m = re.search(r"\{.*\}", text, flags=re.DOTALL)
        if not m:
            raise
        return json.loads(m.group(0))


def fallback_coach(items: List[Dict[str, Any]]) -> Dict[str, Any]:
    if not items:
        return {"top_causes": [], "tone_note": "ê¸°ë¡ì´ ë¹„ì–´ ìˆì–´ ë¶„ì„ ëŒ€ì‹  ë‹¤ìŒ ê¸°ë¡ì„ ê¸°ë‹¤ë¦¬ê³  ìˆì–´ìš”."}

    df = pd.DataFrame(items)
    # count by cause
    counts = df["cause"].value_counts().head(3)

    top_causes = []
    for cause, _cnt in counts.items():
        sub = df[df["cause"] == cause]
        repeated = bool(sub["repeated_2w"].fillna(False).any())

        actionable = [
            "ì‹¤íŒ¨ê°€ ë‚œ ë‚ ì˜ 'ì²« ì¥ì• ë¬¼'ë§Œ í•œ ë¬¸ì¥ìœ¼ë¡œ ì ê³ , ë‚´ì¼ì€ ê·¸ ì¥ì• ë¬¼ì„ í”¼í•˜ëŠ” ì¥ì¹˜ë¥¼ ë”± 1ê°œë§Œ ì¶”ê°€í•´ìš”(ì˜ˆ: íšŒì˜ í›„ 10ë¶„ íœ´ì‹ ê³ ì •).",
            "ê³„íšì„ 'ì‹œì‘ 2ë¶„ ë²„ì „'ìœ¼ë¡œ ì¶•ì†Œí•´ì„œ ì§„ì…ì¥ë²½ì„ ë‚®ì¶°ìš”(ì˜ˆ: ìš´ë™ 20ë¶„ â†’ ìŠ¤íŠ¸ë ˆì¹­ 2ë¶„ë§Œ).",
            "ì‹¤íŒ¨ê°€ ë§ì´ ë‚˜ëŠ” ì‹œê°„ëŒ€ë¥¼ íŒŒì•…í•´ì„œ, ê·¸ ì‹œê°„ì—” ë°©í•´ìš”ì¸ì„ ë¯¸ë¦¬ ì¹˜ìš°ëŠ” ë£¨í‹´(ì•Œë¦¼ ë„ê¸°/ì¥ì†Œ ì´ë™/ë„êµ¬ ë¯¸ë¦¬ ì¤€ë¹„)ì„ ë§Œë“¤ì–´ìš”.",
        ]
        creative = []
        if repeated:
            creative = [
                "2ì£¼ ì´ìƒ ë°˜ë³µì´ë©´, ëª©í‘œë¥¼ 'ì„±ê³¼'ê°€ ì•„ë‹ˆë¼ 'ì¡°ê±´ ì‹¤í—˜'ìœ¼ë¡œ ë°”ê¿”ìš”. ì˜ˆ: 'ìš´ë™ ì„±ê³µ' â†’ 'ìš´ë™ì´ ë˜ëŠ” ì¡°ê±´ ì°¾ê¸°'ë¥¼ 1ì£¼ì¼ë§Œ ì‹¤í—˜.",
                "íŠ¸ë¦¬ê±°ë¥¼ ì™„ì „íˆ ë°”ê¿”ë´ìš”. ì‹œê°„(ì €ë…â†’ì•„ì¹¨), ì¥ì†Œ(ì§‘â†’ì¹´í˜/í—¬ìŠ¤ì¥), ë°©ì‹(í˜¼ìâ†’ë™ë£Œ/í´ë˜ìŠ¤) ì¤‘ í•˜ë‚˜ë§Œ êµì²´í•´ìš”.",
            ]

        top_causes.append(
            {
                "cause": cause,
                "summary": f"ìµœê·¼ ê¸°ë¡ì—ì„œ '{cause}' ìœ í˜•ì´ ìì£¼ ë“±ì¥í•´ìš”. ì´ê±´ ì˜ì§€ ë¬¸ì œê°€ ì•„ë‹ˆë¼ 'ì¡°ê±´/ì„¤ê³„' ì¡°ì •ìœ¼ë¡œ ê°œì„ ë  ê°€ëŠ¥ì„±ì´ í° ì‹ í˜¸ì˜ˆìš”.",
                "actionable_advice": actionable,
                "creative_advice_when_repeated_2w": creative if repeated else [],
            }
        )

    return {"top_causes": top_causes, "tone_note": "ì‹¤íŒ¨ë¥¼ íƒ“ì´ ì•„ë‹ˆë¼ 'ì¡°ì • ê°€ëŠ¥í•œ ì¡°ê±´ ë°ì´í„°'ë¡œ ë‹¤ë£¨ëŠ” í†¤ì„ ìœ ì§€í–ˆì–´ìš”."}


def run_coaching(items: List[Dict[str, Any]]) -> Tuple[Dict[str, Any], str]:
    try:
        return openai_coach(items), "OpenAI"
    except Exception:
        return fallback_coach(items), "Local"


# -----------------------------
# Reminder: in-app + .ics
# -----------------------------
def parse_hhmm(s: str) -> time:
    s = s.strip()
    m = re.match(r"^(\d{1,2}):(\d{2})$", s)
    if not m:
        return time(21, 30)
    hh, mm = int(m.group(1)), int(m.group(2))
    hh = max(0, min(23, hh))
    mm = max(0, min(59, mm))
    return time(hh, mm)


def should_show_reminder(now_dt: datetime, reminder_t: time, window_min: int) -> bool:
    target = datetime.combine(now_dt.date(), reminder_t)
    delta = abs((now_dt - target).total_seconds()) / 60.0
    return delta <= float(window_min)


def count_pending_today(d: date) -> int:
    ensure_daily_rows(d)
    conn = get_conn()
    cur = conn.cursor()
    row = cur.execute(
        """
        SELECT COUNT(*) FROM daily_logs dl
        JOIN plans p ON p.id=dl.plan_id
        WHERE dl.log_date=? AND p.active=1 AND dl.status='pending'
        """,
        (d.isoformat(),),
    ).fetchone()
    conn.close()
    return int(row[0] if row else 0)


def build_daily_ics(reminder_t: time) -> str:
    # Recurring daily event, floating local time
    dtstamp = datetime.utcnow().strftime("%Y%m%dT%H%M%SZ")
    start = datetime.combine(today_local(), reminder_t).strftime("%Y%m%dT%H%M%S")
    uid = f"failog-reminder-{dtstamp}@local"
    # Keep it simple; users can import into Google/Apple Calendar.
    ics = f"""BEGIN:VCALENDAR
VERSION:2.0
PRODID:-//failog//Reminder//EN
CALSCALE:GREGORIAN
BEGIN:VEVENT
UID:{uid}
DTSTAMP:{dtstamp}
DTSTART:{start}
DURATION:PT10M
RRULE:FREQ=DAILY
SUMMARY:failog ë°ì¼ë¦¬ ì²´í¬ ë¦¬ë§ˆì¸ë”
DESCRIPTION:ì˜¤ëŠ˜ì˜ ê³„íšì„ ì„±ê³µ/ì‹¤íŒ¨ë¡œ ì²´í¬í•˜ê³ , ì‹¤íŒ¨ë¼ë©´ ì´ìœ ë¥¼ í•œ ë¬¸ì¥ ê¸°ë¡í•´ìš”.
END:VEVENT
END:VCALENDAR
"""
    return ics


# -----------------------------
# UI
# -----------------------------
def main():
    st.set_page_config(page_title="failog", page_icon="ğŸ§­", layout="wide")
    init_db()

    # Reminder polling
    reminder_enabled = get_setting("reminder_enabled", "true").lower() == "true"
    reminder_time = parse_hhmm(get_setting("reminder_time", "21:30"))
    reminder_window = int(get_setting("reminder_window_min", "15"))
    poll_sec = int(get_setting("reminder_poll_sec", "60"))

    if reminder_enabled and st_autorefresh is not None:
        st_autorefresh(interval=poll_sec * 1000, key="reminder_refresh")

    # In-app reminder banner
    if reminder_enabled:
        pending = count_pending_today(today_local())
        if pending > 0 and should_show_reminder(datetime.now(), reminder_time, reminder_window):
            st.toast(f"ë¦¬ë§ˆì¸ë”: ì•„ì§ ì²´í¬í•˜ì§€ ì•Šì€ í•­ëª©ì´ {pending}ê°œ ìˆì–´ìš”. (ì˜¤ëŠ˜ë§Œ ê°€ë³ê²Œ ì •ë¦¬í•´ë„ ì¶©ë¶„í•´ìš”)", icon="â°")
            st.info(f"â° ì˜¤ëŠ˜ ì²´í¬ê°€ ì•„ì§ {pending}ê°œ ë‚¨ì•„ ìˆì–´ìš”. ì‹¤íŒ¨ì—¬ë„ ê´œì°®ì•„ìš”. í•œ ë¬¸ì¥ë§Œ ë‚¨ê¸°ë©´ ë‚´ì¼ì´ ì‰¬ì›Œì ¸ìš”.")

    st.title(APP_TITLE)
    st.caption("ì‹¤íŒ¨ëŠ” ë°ì´í„°ì˜ˆìš”. ë¹„ë‚œ ì—†ì´, ì¡°ê±´ì„ ì¡°ì •í•˜ëŠ” ì½”ì¹­ìœ¼ë¡œ ë°”ê¿”ìš”.")

    with st.expander("ğŸ” OpenAI ì„¤ì •(ì„ íƒ)", expanded=False):
        st.write("- í™˜ê²½ë³€ìˆ˜ `OPENAI_API_KEY`ê°€ ìˆìœ¼ë©´ ë” ì„¬ì„¸í•œ ë¶„ë¥˜/ì½”ì¹­ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        st.write("- ì—†ìœ¼ë©´ ë¡œì»¬ ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ ë™ì‘í•©ë‹ˆë‹¤.")
        st.code(
            "export OPENAI_API_KEY='YOUR_KEY'\n"
            "export FAILOG_OPENAI_MODEL='gpt-4o-mini'  # ì„ íƒ\n"
            "streamlit run failog_app.py",
            language="bash",
        )

    tab_daily, tab_report, tab_analysis, tab_manage = st.tabs(
        ["âœ… ë°ì¼ë¦¬ ì²´í¬", "ğŸ—“ï¸ ì£¼ê°„ ë¦¬í¬íŠ¸", "ğŸ“ˆ ì›ì¸ íŠ¸ë Œë“œ & ì½”ì¹­", "âš™ï¸ ê´€ë¦¬(ê³„íš/ì›ì¸/ì•Œë¦¼)"]
    )

    # -------------------------
    # Tab 1: Daily
    # -------------------------
    with tab_daily:
        colL, colR = st.columns([1, 2])

        with colL:
            selected_date = st.date_input("ë‚ ì§œ", value=today_local(), key="daily_date")
            ensure_daily_rows(selected_date)
            st.subheader("ì˜¤ëŠ˜ì˜ í•œ ì¤„ ì½”ì¹­")
            st.write("ì‹¤íŒ¨ëŠ” â€˜ë‚´ê°€ ë¶€ì¡±í•¨â€™ì´ ì•„ë‹ˆë¼, **ì¡°ê±´ì´ ì•ˆ ë§ì•˜ë‹¤ëŠ” ì‹ í˜¸**ì¼ ë•Œê°€ ë§ì•„ìš”.")

        with colR:
            st.subheader("ë°ì¼ë¦¬ ê³„íš ë¦¬ìŠ¤íŠ¸")
            df = get_daily_logs(selected_date)
            causes_df = list_causes(active_only=True)
            cause_names = causes_df["name"].tolist()

            if df.empty:
                st.warning("í™œì„±í™”ëœ ê³„íšì´ ì—†ì–´ìš”. 'ê´€ë¦¬'ì—ì„œ ê³„íšì„ ì¶”ê°€í•´ ì£¼ì„¸ìš”.")
            else:
                for _, row in df.iterrows():
                    with st.container(border=True):
                        c1, c2 = st.columns([4, 6])
                        with c1:
                            st.markdown(f"**{row['plan_title']}**")
                            st.caption(f"ìƒíƒœ: `{row['status']}`")
                            if row.get("cause_name"):
                                st.caption(f"ì›ì¸: {row['cause_name']} ({row.get('cause_source','')}, {row.get('cause_confidence',0):.2f})")

                        with c2:
                            b1, b2, b3 = st.columns([1, 1, 1])
                            with b1:
                                if st.button("ì„±ê³µ âœ…", key=f"succ_{row['id']}"):
                                    update_log_success(int(row["id"]))
                                    st.success("ì„±ê³µ ì²´í¬ ì™„ë£Œ!")
                                    st.rerun()
                            with b2:
                                if st.button("ëŒ€ê¸° â†©ï¸", key=f"pend_{row['id']}"):
                                    update_log_pending(int(row["id"]))
                                    st.info("ëŒ€ê¸°ë¡œ ë˜ëŒë ¸ì–´ìš”.")
                                    st.rerun()
                            with b3:
                                # placeholder for spacing
                                st.write("")

                            reason_key = f"reason_{row['id']}"
                            cause_key = f"cause_{row['id']}"

                            default_reason = row["reason"] if row["reason"] else ""
                            reason = st.text_input("ì‹¤íŒ¨ ì´ìœ (í•œ ë¬¸ì¥)", value=default_reason, key=reason_key)

                            # cause selection
                            default_cause = row["cause_name"] if row["cause_name"] in cause_names else "ìë™ ë¶„ë¥˜"
                            options = ["ìë™ ë¶„ë¥˜"] + cause_names
                            cause_sel = st.selectbox("ì›ì¸ ì¹´í…Œê³ ë¦¬", options=options, index=options.index(default_cause) if default_cause in options else 0, key=cause_key)

                            if st.button("ì‹¤íŒ¨ âŒ ì €ì¥", key=f"fail_save_{row['id']}"):
                                if cause_sel == "ìë™ ë¶„ë¥˜":
                                    cause, conf, src = classify_reason(reason, prefer_openai=True)
                                else:
                                    cause, conf, src = cause_sel, 1.0, "user"
                                update_log_fail(int(row["id"]), reason, cause, src, conf)
                                st.warning("ì‹¤íŒ¨ ì²´í¬ ì €ì¥ ì™„ë£Œ! ê¸°ë¡ì„ ë‚¨ê¸´ ê²ƒ ìì²´ê°€ ì´ë¯¸ ë‹¤ìŒ ì„±ê³µ í™•ë¥ ì„ ì˜¬ë ¸ì–´ìš”.")
                                st.rerun()

    # -------------------------
    # Tab 2: Weekly Report
    # -------------------------
    with tab_report:
        st.subheader("ìŠµê´€/ëª©í‘œë³„ ì£¼ê°„ ë¦¬í¬íŠ¸")
        end_d = st.date_input("ë¦¬í¬íŠ¸ ì¢…ë£Œì¼", value=today_local(), key="report_end")
        ws = week_start(end_d)
        we = ws + timedelta(days=6)
        st.caption(f"ì£¼ê°„ ë²”ìœ„: {ws.isoformat()} ~ {we.isoformat()} (ì›”~ì¼)")

        logs = get_logs_range(ws, we, active_only=False)
        if logs.empty:
            st.info("ì´ ì£¼ì°¨ì—ëŠ” ê¸°ë¡ì´ ì—†ì–´ìš”.")
        else:
            # overall summary by plan
            def plan_week_summary(df: pd.DataFrame) -> pd.DataFrame:
                x = df.copy()
                x["is_success"] = (x["status"] == "success").astype(int)
                x["is_fail"] = (x["status"] == "fail").astype(int)
                x["is_pending"] = (x["status"] == "pending").astype(int)
                g = x.groupby(["plan_id", "plan_title"], as_index=False).agg(
                    success=("is_success", "sum"),
                    fail=("is_fail", "sum"),
                    pending=("is_pending", "sum"),
                )
                g["checked"] = g["success"] + g["fail"]
                g["success_rate"] = g.apply(lambda r: (r["success"] / r["checked"]) if r["checked"] else 0.0, axis=1)
                return g.sort_values(["success_rate", "checked"], ascending=[False, False])

            summary = plan_week_summary(logs)
            summary_show = summary.copy()
            summary_show["success_rate"] = (summary_show["success_rate"] * 100).round(1).astype(str) + "%"
            st.dataframe(summary_show, use_container_width=True, hide_index=True)

            # per-plan details
            st.markdown("### ê³„íšë³„ ìƒì„¸")
            failures = logs[logs["status"] == "fail"].copy()
            failures["cause_name"] = failures["cause_name"].fillna("ê¸°íƒ€(ëª…í™•í™” í•„ìš”)")
            repeated_flags = detect_repeated_causes_2w(
                get_failures(ws - timedelta(days=21), we)  # look-back í¬í•¨: ë°˜ë³µ ê°ì§€ì— ìœ ë¦¬
            )

            plans = summary[["plan_id", "plan_title"]].values.tolist()
            for pid, title in plans:
                with st.container(border=True):
                    st.markdown(f"#### {title}")
                    sub = logs[logs["plan_id"] == pid].copy()
                    # streak calculation (simple: consecutive successes ending at week end)
                    sub["log_date"] = pd.to_datetime(sub["log_date"]).dt.date
                    sub_sorted = sub.sort_values("log_date")
                    streak = 0
                    # calculate ending streak up to we
                    by_date = {r["log_date"]: r["status"] for _, r in sub_sorted.iterrows()}
                    d = we
                    while d >= ws:
                        stt = by_date.get(d, "pending")
                        if stt == "success":
                            streak += 1
                            d -= timedelta(days=1)
                        else:
                            break

                    succ = int((sub["status"] == "success").sum())
                    fail = int((sub["status"] == "fail").sum())
                    pend = int((sub["status"] == "pending").sum())
                    checked = succ + fail
                    rate = (succ / checked) if checked else 0.0

                    c1, c2, c3, c4 = st.columns(4)
                    c1.metric("ì„±ê³µ", succ)
                    c2.metric("ì‹¤íŒ¨", fail)
                    c3.metric("ëŒ€ê¸°", pend)
                    c4.metric("ì£¼ê°„ ì„±ê³µë¥ ", f"{rate*100:.1f}%")

                    st.caption(f"ì£¼ê°„ ë§ˆê° ê¸°ì¤€ ì—°ì† ì„±ê³µ(ëŒ€ëµ): {streak}ì¼")

                    # Top causes
                    fsub = failures[failures["plan_id"] == pid]
                    if fsub.empty:
                        st.success("ì´ë²ˆ ì£¼ì—ëŠ” ì‹¤íŒ¨ ê¸°ë¡ì´ ì—†ì–´ìš”. ì´ í˜ì´ìŠ¤ê°€ â€˜ê¸°ë³¸ê°’â€™ì´ ë˜ë„ë¡ ê°€ë³ê²Œ ìœ ì§€í•´ìš”.")
                    else:
                        topc = fsub["cause_name"].value_counts().head(3)
                        st.write("ì‹¤íŒ¨ Top ì›ì¸:")
                        for cause, cnt in topc.items():
                            rep = repeated_flags.get((int(pid), str(cause)), False)
                            tag = " (2ì£¼+ ë°˜ë³µ ì‹ í˜¸)" if rep else ""
                            st.write(f"- {cause}: {cnt}íšŒ{tag}")

                        with st.expander("ì‹¤íŒ¨ ê¸°ë¡(ì´ìœ /ì›ì¸) ë³´ê¸°", expanded=False):
                            view = fsub[["log_date", "reason", "cause_name", "cause_source", "cause_confidence"]].copy()
                            st.dataframe(view, use_container_width=True, hide_index=True)

    # -------------------------
    # Tab 3: Trends & Coaching
    # -------------------------
    with tab_analysis:
        st.subheader("ì›ì¸ ì¹´í…Œê³ ë¦¬ íŠ¸ë Œë“œ & ì½”ì¹­")
        colA, colB, colC = st.columns([1, 1, 2])
        with colA:
            days = st.selectbox("ë¶„ì„ ê¸°ê°„(ì¼)", [7, 14, 21, 30, 60, 90], index=1, key="an_days")
        with colB:
            end_d = st.date_input("ì¢…ë£Œì¼", value=today_local(), key="an_end")
        with colC:
            st.caption("ì €ì¥ëœ ì›ì¸ ì¹´í…Œê³ ë¦¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ íŒŒì´/íŠ¸ë Œë“œë¥¼ ê·¸ë¦¬ê³ , ê³µí†µ ì›ì¸ 3ê°œ ì´ë‚´ ì½”ì¹­ì„ ìƒì„±í•´ìš”.")
            st.caption("ê°™ì€ ì›ì¸ì´ 2ì£¼ ì´ìƒ ë°˜ë³µë˜ë©´(ì›ì¸ ë‹¨ìœ„) í•´ë‹¹ ì›ì¸ì— ì°½ì˜ì  ëŒ€ì•ˆì„ ì¶”ê°€í•©ë‹ˆë‹¤.")

        start_d = end_d - timedelta(days=int(days) - 1)

        failures_df = get_failures(start_d, end_d)

        # Backfill missing causes in the window (optional toggle)
        st.markdown("#### ì›ì¸ ì €ì¥ ìƒíƒœ")
        missing = int(failures_df["cause_name"].isna().sum()) if not failures_df.empty else 0
        st.write(f"- ì´ ê¸°ê°„ ì‹¤íŒ¨ ì¤‘ ì›ì¸ ë¯¸ì €ì¥: **{missing}ê±´**")
        backfill = st.checkbox("ì´ ê¸°ê°„ì˜ ì›ì¸ ë¯¸ì €ì¥ ì‹¤íŒ¨ë¥¼ ìë™ ë¶„ë¥˜í•´ì„œ DBì— ì €ì¥(ì¶”ì²œ)", value=False)

        if backfill and missing > 0:
            # classify and store
            for _, r in failures_df[failures_df["cause_name"].isna()].iterrows():
                cid = int(r["id"])
                reason = r["reason"] or ""
                cause, conf, src = classify_reason(reason, prefer_openai=True)
                # update row without changing status
                conn = get_conn()
                conn.execute(
                    """
                    UPDATE daily_logs
                    SET cause_name=?, cause_source=?, cause_confidence=?, cause_updated_at=?, updated_at=?
                    WHERE id=?
                    """,
                    (cause, src, float(conf), now_iso(), now_iso(), cid),
                )
                conn.commit()
                conn.close()
            st.success("ìë™ ë¶„ë¥˜ ì €ì¥ ì™„ë£Œ! (ì´ì œ ë‹¤ìŒ ë¶„ì„ì´ ë” ì •í™•í•´ì ¸ìš”)")
            failures_df = get_failures(start_d, end_d)

        if failures_df.empty:
            st.info("ì´ ê¸°ê°„ì—” ì‹¤íŒ¨ ê¸°ë¡ì´ ì—†ì–´ìš”. ğŸ‘ ì§€ê¸ˆì˜ ë¦¬ë“¬ì„ ìœ ì§€í•´ë„ ì¶©ë¶„íˆ ì¢‹ìŠµë‹ˆë‹¤.")
        else:
            # normalize cause
            failures_df = failures_df.copy()
            failures_df["cause_name"] = failures_df["cause_name"].fillna("ê¸°íƒ€(ëª…í™•í™” í•„ìš”)")
            failures_df["log_date"] = pd.to_datetime(failures_df["log_date"]).dt.date

            # Pie chart
            st.markdown("#### ì›ì¸ ë¶„í¬(íŒŒì´)")
            pie_df = failures_df["cause_name"].value_counts().reset_index()
            pie_df.columns = ["cause", "count"]
            st.dataframe(pie_df, use_container_width=True, hide_index=True)
            # Streamlit native charts are limited; use bar as a clear default
            st.bar_chart(pie_df.set_index("cause"))

            # Trend (weekly)
            st.markdown("#### ì›ì¸ íŠ¸ë Œë“œ(ì£¼ì°¨ë³„)")
            tmp = failures_df.copy()
            tmp["week"] = tmp["log_date"].apply(lambda d: week_start(d).isoformat())
            trend = tmp.groupby(["week", "cause_name"]).size().reset_index(name="count")
            pivot = trend.pivot(index="week", columns="cause_name", values="count").fillna(0).sort_index()
            st.line_chart(pivot)

            # Repeated cause flags (within window)
            repeated_flags = detect_repeated_causes_2w(failures_df)

            # Build coaching payload (cause-based)
            items = []
            for _, r in failures_df.iterrows():
                pid = int(r["plan_id"])
                cause = str(r["cause_name"])
                items.append(
                    {
                        "plan_title": r["plan_title"],
                        "date": str(r["log_date"]),
                        "reason": r["reason"] or "",
                        "cause": cause,
                        "repeated_2w": bool(repeated_flags.get((pid, cause), False)),
                    }
                )

            st.markdown("#### ì½”ì¹­ ìƒì„±")
            colX, colY = st.columns([1, 3])
            with colX:
                run_btn = st.button("ì½”ì¹­ ìƒì„±/ê°±ì‹ ", type="primary", key="coach_run")
            with colY:
                st.caption("OpenAI í‚¤ê°€ ìˆìœ¼ë©´ ë” ìì—°ìŠ¤ëŸ½ê³  ì„¬ì„¸í•˜ê²Œ, ì—†ìœ¼ë©´ ë¡œì»¬ ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ ì½”ì¹­ì„ ìƒì„±í•©ë‹ˆë‹¤.")

            if run_btn or ("coach_result" not in st.session_state):
                result, engine = run_coaching(items)
                st.session_state["coach_result"] = result
                st.session_state["coach_engine"] = engine

            result = st.session_state.get("coach_result", {})
            engine = st.session_state.get("coach_engine", "Local")
            st.write(f"ì‚¬ìš© ì—”ì§„: **{engine}**")

            top_causes = result.get("top_causes", []) if isinstance(result.get("top_causes", []), list) else []
            if not top_causes:
                st.info("ì•„ì§ ë¶„ë¥˜í•  ë§Œí¼ ë°ì´í„°ê°€ ë¶€ì¡±í•´ìš”. ì‹¤íŒ¨ ì´ìœ ë¥¼ í•œ ë¬¸ì¥ì´ë¼ë„ ë” ìŒ“ì•„ë³´ë©´ ì •í™•ë„ê°€ ì˜¬ë¼ê°€ìš”.")
            else:
                st.markdown("### ê³µí†µ ì›ì¸ TOP (ìµœëŒ€ 3)")
                for i, c in enumerate(top_causes, start=1):
                    with st.container(border=True):
                        st.markdown(f"### {i}) {c.get('cause','(ì›ì¸)')}")
                        st.write(c.get("summary", ""))

                        st.markdown("**ì‹¤í–‰ ê°€ëŠ¥í•œ ê°œì„  ì¡°ì–¸(í˜„ì‹¤ ë²„ì „)**")
                        for tip in (c.get("actionable_advice") or [])[:6]:
                            st.write(f"- {tip}")

                        creative = c.get("creative_advice_when_repeated_2w") or []
                        if creative:
                            st.markdown("**2ì£¼ ì´ìƒ ë°˜ë³µ ì‹œ: ì™„ì „íˆ ë‹¤ë¥¸ ê°ë„ì˜ ëŒ€ì•ˆ(ì°½ì˜ ë²„ì „)**")
                            for tip in creative[:6]:
                                st.write(f"- {tip}")

                st.caption(result.get("tone_note", ""))

            with st.expander("ğŸ” ì´ë²ˆ ë¶„ì„ì— ì‚¬ìš©ëœ ë°ì´í„° ë³´ê¸°", expanded=False):
                st.dataframe(pd.DataFrame(items), use_container_width=True, hide_index=True)

    # -------------------------
    # Tab 4: Manage (Plans / Causes / Reminder)
    # -------------------------
    with tab_manage:
        st.subheader("ê´€ë¦¬")

        subtab_plans, subtab_causes, subtab_reminder, subtab_fix = st.tabs(
            ["ê³„íš", "ì›ì¸ ì¹´í…Œê³ ë¦¬", "ì•Œë¦¼(ë¦¬ë§ˆì¸ë”)", "ë°ì´í„° ì •ë¦¬/ìˆ˜ì •"]
        )

        # Plans
        with subtab_plans:
            col1, col2 = st.columns([2, 3])
            with col1:
                st.markdown("#### ìƒˆ ê³„íš ì¶”ê°€")
                new_title = st.text_input("ê³„íš/ìŠµê´€ ì´ë¦„", placeholder="ì˜ˆ: ì˜ì–´ ë‹¨ì–´ 20ê°œ / ìš´ë™ 20ë¶„ / ë…¼ë¬¸ 1í˜ì´ì§€", key="new_plan")
                if st.button("ì¶”ê°€", key="add_plan_btn"):
                    if not new_title.strip():
                        st.error("ê³„íš ì´ë¦„ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
                    else:
                        add_plan(new_title.strip())
                        st.success("ì¶”ê°€ ì™„ë£Œ!")
                        st.rerun()

                st.markdown("---")
                st.markdown("#### ìš´ì˜ íŒ")
                st.write("- ê³„íšì€ ì‘ì„ìˆ˜ë¡ ì„±ê³µë¥ ì´ ì˜¬ë¼ê°€ìš”.")
                st.write("- ì‹¤íŒ¨ ì´ìœ ëŠ” ê¸¸ê²Œ ì“°ì§€ ì•Šì•„ë„ ë¼ìš”. í•œ ë¬¸ì¥ìœ¼ë¡œ ì¶©ë¶„í•´ìš”.")
                st.write("- ë°˜ë³µ ì‹¤íŒ¨ëŠ” â€˜ì˜ì§€â€™ë³´ë‹¤ ì„¤ê³„/í™˜ê²½ì˜ ì‹ í˜¸ì¼ ë•Œê°€ ë§ì•„ìš”.")

            with col2:
                st.markdown("#### ë‚´ ê³„íš ëª©ë¡")
                plans_df = list_plans(active_only=False)
                if plans_df.empty:
                    st.info("ì•„ì§ ê³„íšì´ ì—†ì–´ìš”. ì™¼ìª½ì—ì„œ ì¶”ê°€í•´ ì£¼ì„¸ìš”.")
                else:
                    for _, r in plans_df.iterrows():
                        with st.container(border=True):
                            a, b, c = st.columns([4, 2, 2])
                            with a:
                                st.markdown(f"**{r['title']}**")
                                st.caption(f"ìƒì„±: {r['created_at']}")
                            with b:
                                active = bool(r["active"])
                                st.write("ìƒíƒœ:", "í™œì„± âœ…" if active else "ë¹„í™œì„± â›”")
                            with c:
                                if active:
                                    if st.button("ë¹„í™œì„±í™”", key=f"deact_{r['id']}"):
                                        set_plan_active(int(r["id"]), False)
                                        st.rerun()
                                else:
                                    if st.button("í™œì„±í™”", key=f"act_{r['id']}"):
                                        set_plan_active(int(r["id"]), True)
                                        st.rerun()

        # Causes taxonomy
        with subtab_causes:
            st.markdown("#### ì›ì¸ ì¹´í…Œê³ ë¦¬ ëª©ë¡(ë¶„ë¥˜ ê¸°ì¤€)")
            causes_df = list_causes(active_only=False)
            if causes_df.empty:
                st.warning("ì›ì¸ ì¹´í…Œê³ ë¦¬ê°€ ì—†ì–´ìš”.")
            else:
                for _, r in causes_df.iterrows():
                    with st.container(border=True):
                        c1, c2, c3 = st.columns([3, 5, 2])
                        with c1:
                            st.markdown(f"**{r['name']}**")
                            st.caption("í™œì„± âœ…" if int(r["active"]) == 1 else "ë¹„í™œì„± â›”")
                        with c2:
                            st.write(r["description"] or "")
                            try:
                                kws = json.loads(r["keywords"] or "[]")
                            except Exception:
                                kws = []
                            if kws:
                                st.caption("í‚¤ì›Œë“œ: " + ", ".join(kws))
                        with c3:
                            if int(r["active"]) == 1:
                                if st.button("ë¹„í™œì„±í™”", key=f"cause_off_{r['id']}"):
                                    set_cause_active(int(r["id"]), False)
                                    st.rerun()
                            else:
                                if st.button("í™œì„±í™”", key=f"cause_on_{r['id']}"):
                                    set_cause_active(int(r["id"]), True)
                                    st.rerun()

            st.markdown("---")
            st.markdown("#### ìƒˆ ì›ì¸ ì¹´í…Œê³ ë¦¬ ì¶”ê°€")
            name = st.text_input("ì´ë¦„", placeholder="ì˜ˆ: ì¥ì†Œ/ë„êµ¬ ë¬¸ì œ", key="cause_new_name")
            desc = st.text_area("ì„¤ëª…", placeholder="ì´ ì¹´í…Œê³ ë¦¬ê°€ í¬í•¨í•˜ëŠ” ì‹¤íŒ¨ì˜ ê³µí†µ íŠ¹ì§•", key="cause_new_desc")
            kws_raw = st.text_input("í‚¤ì›Œë“œ(ì‰¼í‘œë¡œ êµ¬ë¶„)", placeholder="ì˜ˆ: ì¥ì†Œ, ì¹´í˜, ë…¸íŠ¸ë¶, ì¤€ë¹„ë¬¼", key="cause_new_kws")
            if st.button("ì›ì¸ ì¶”ê°€", key="cause_add_btn"):
                if not name.strip():
                    st.error("ì´ë¦„ì€ í•„ìˆ˜ì˜ˆìš”.")
                else:
                    kws = [x.strip() for x in kws_raw.split(",") if x.strip()]
                    try:
                        add_cause(name, desc, kws)
                        st.success("ì¶”ê°€ ì™„ë£Œ!")
                        st.rerun()
                    except sqlite3.IntegrityError:
                        st.error("ì´ë¯¸ ê°™ì€ ì´ë¦„ì˜ ì›ì¸ì´ ìˆì–´ìš”. ì´ë¦„ì„ ë°”ê¿”ì£¼ì„¸ìš”.")

        # Reminder
        with subtab_reminder:
            st.markdown("#### ë¦¬ë§ˆì¸ë” ì„¤ì •")
            enabled = st.toggle("ë¦¬ë§ˆì¸ë” ì¼œê¸°", value=reminder_enabled, key="rem_en")
            rt = st.text_input("ë¦¬ë§ˆì¸ë” ì‹œê°„(HH:MM)", value=get_setting("reminder_time", "21:30"), key="rem_time")
            wm = st.number_input("í‘œì‹œ í—ˆìš© ì˜¤ì°¨(ë¶„)", min_value=1, max_value=120, value=int(get_setting("reminder_window_min", "15")), key="rem_win")
            ps = st.number_input("ì•± ë‚´ ì²´í¬ ì£¼ê¸°(ì´ˆ)", min_value=10, max_value=600, value=int(get_setting("reminder_poll_sec", "60")), key="rem_poll")

            if st.button("ì„¤ì • ì €ì¥", key="rem_save"):
                upsert_setting("reminder_enabled", "true" if enabled else "false")
                upsert_setting("reminder_time", rt.strip())
                upsert_setting("reminder_window_min", str(int(wm)))
                upsert_setting("reminder_poll_sec", str(int(ps)))
                st.success("ì €ì¥í–ˆì–´ìš”. (ì•±ì´ ì¼œì ¸ ìˆì„ ë•Œ ì„¤ì • ì‹œê°„ì— ë°°ë„ˆê°€ ë– ìš”)")
                st.rerun()

            st.markdown("---")
            st.markdown("#### ìº˜ë¦°ë”(êµ¬ê¸€/ì• í”Œ ë“±)ë¡œ ë¦¬ë§ˆì¸ë” ë°›ê¸°(.ics)")
            t = parse_hhmm(rt)
            ics = build_daily_ics(t)
            st.download_button(
                "ğŸ“¥ ë§¤ì¼ ë¦¬ë§ˆì¸ë” .ics ë‹¤ìš´ë¡œë“œ",
                data=ics.encode("utf-8"),
                file_name="failog_daily_reminder.ics",
                mime="text/calendar",
            )
            st.caption("ë‹¤ìš´ë¡œë“œ í›„ ìº˜ë¦°ë”ì— ê°€ì ¸ì˜¤ê¸°(import) í•˜ë©´, ì•±ì„ ì•ˆ ì¼œë„ OS/ìº˜ë¦°ë” ì•Œë¦¼ì„ ë°›ì„ ìˆ˜ ìˆì–´ìš”.")

        # Fix / Edit existing causes on logs (manual correction)
        with subtab_fix:
            st.markdown("#### ì‹¤íŒ¨ ê¸°ë¡ì˜ ì›ì¸ ìˆ˜ì •(ì •í™•ë„ ê°œì„ )")
            d1 = st.date_input("ì‹œì‘ì¼", value=today_local() - timedelta(days=14), key="fix_s")
            d2 = st.date_input("ì¢…ë£Œì¼", value=today_local(), key="fix_e")
            df = get_failures(d1, d2)
            if df.empty:
                st.info("ì„ íƒí•œ ê¸°ê°„ì— ì‹¤íŒ¨ ê¸°ë¡ì´ ì—†ì–´ìš”.")
            else:
                df = df.copy()
                df["cause_name"] = df["cause_name"].fillna("ê¸°íƒ€(ëª…í™•í™” í•„ìš”)")
                st.dataframe(df[["id", "log_date", "plan_title", "reason", "cause_name", "cause_source", "cause_confidence"]],
                             use_container_width=True, hide_index=True)

                st.markdown("ì›ì¸ ìˆ˜ì •:")
                causes_df = list_causes(active_only=True)
                cause_names = causes_df["name"].tolist()
                target_id = st.number_input("ìˆ˜ì •í•  log id", min_value=int(df["id"].min()), max_value=int(df["id"].max()), value=int(df["id"].min()), step=1)
                new_cause = st.selectbox("ìƒˆ ì›ì¸", options=cause_names, index=0)
                if st.button("ì›ì¸ ì—…ë°ì´íŠ¸", key="fix_update"):
                    conn = get_conn()
                    conn.execute(
                        """
                        UPDATE daily_logs
                        SET cause_name=?, cause_source='user', cause_confidence=1.0, cause_updated_at=?, updated_at=?
                        WHERE id=?
                        """,
                        (new_cause, now_iso(), now_iso(), int(target_id)),
                    )
                    conn.commit()
                    conn.close()
                    st.success("ì—…ë°ì´íŠ¸ ì™„ë£Œ! ë‹¤ìŒ ë¶„ì„ë¶€í„° ë” ì •í™•í•´ì ¸ìš”.")
                    st.rerun()

    st.markdown("---")
    st.caption(f"Â© failog â€¢ Timezone hint: {DEFAULT_TZ} â€¢ DB: {DB_PATH}")


if __name__ == "__main__":
    main()
